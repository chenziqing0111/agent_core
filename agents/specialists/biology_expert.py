# agent_core/agents/specialists/biology_expert.py
# ä½¿ç”¨å·¥ä½œçš„PubMedæ£€ç´¢å™¨çš„Biology Expert

import asyncio
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import logging

# å¯¼å…¥é…ç½®ç³»ç»Ÿ
try:
    from agent_core.config.analysis_config import (
        AnalysisConfig, AnalysisMode, ConfigManager
    )
except ImportError:
    # å¦‚æœé…ç½®ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•é…ç½®
    class AnalysisMode:
        QUICK = "quick"
        STANDARD = "standard" 
        DEEP = "deep"
    
    @dataclass
    class AnalysisConfig:
        mode: str = "standard"
        max_literature_per_query: int = 10
        tokens_per_analysis: int = 1000
    
    class ConfigManager:
        @staticmethod
        def get_quick_config():
            return AnalysisConfig(mode="quick", max_literature_per_query=5, tokens_per_analysis=500)
        
        @staticmethod
        def get_standard_config():
            return AnalysisConfig(mode="standard", max_literature_per_query=10, tokens_per_analysis=1000)

# å¯¼å…¥å·¥ä½œçš„PubMedæ£€ç´¢å™¨
from agent_core.agents.tools.retrievers.pubmed_retriever import (
    PubMedRetriever, PubMedArticle, PubMedSearchResult, get_pubmed_abstracts
)

logger = logging.getLogger(__name__)

@dataclass
class BiologyAnalysisResult:
    """ç”Ÿç‰©å­¦åˆ†æç»“æœ"""
    gene_target: str
    total_articles: int
    analyzed_articles: int
    
    # æ–‡çŒ®åˆ†æç»“æœ
    key_findings: List[Dict[str, Any]]
    biological_functions: List[str]
    pathways_involved: List[str]
    disease_associations: List[Dict[str, Any]]
    drug_interactions: List[Dict[str, Any]]
    
    # ç ”ç©¶è¶‹åŠ¿
    publication_trends: Dict[str, Any]
    research_hotspots: List[str]
    
    # å…³é”®æ–‡çŒ®
    highly_cited_papers: List[Dict[str, str]]
    recent_discoveries: List[Dict[str, str]]
    
    # åˆ†ææ€»ç»“
    biological_summary: str
    clinical_relevance: str
    research_gaps: List[str]
    
    # å…ƒæ•°æ®
    confidence_score: float
    last_updated: str
    config_used: Dict[str, Any]
    token_usage: Dict[str, int]

class BiologyExpert:
    """
    ç”Ÿç‰©å­¦ä¸“å®¶Agent - ä½¿ç”¨å·¥ä½œçš„PubMedæ£€ç´¢å™¨
    
    Features:
    - åŸºäºå¯é çš„Bio.Entrezçš„æ–‡çŒ®æ£€ç´¢
    - åŸºå› åŠŸèƒ½å’Œé€šè·¯åˆ†æ
    - ç–¾ç—…å…³è”åˆ†æ
    - è¯ç‰©ç›¸äº’ä½œç”¨æŒ–æ˜
    - ç ”ç©¶è¶‹åŠ¿åˆ†æ
    """
    
    def __init__(self, config: AnalysisConfig = None):
        self.name = "Biology Expert"
        self.version = "2.1.0"
        self.expertise = [
            "gene_function_analysis",
            "pathway_analysis", 
            "disease_association",
            "literature_mining",
            "biomarker_discovery"
        ]
        
        # ä½¿ç”¨é…ç½®
        self.config = config or ConfigManager.get_standard_config()
        
        logger.info(f"åˆå§‹åŒ– {self.name} v{self.version} - æ¨¡å¼: {self.config.mode}")
        
    async def analyze(self, gene_target: str, focus_areas: List[str] = None) -> BiologyAnalysisResult:
        """
        æ‰§è¡ŒåŸºå› çš„ç”Ÿç‰©å­¦åˆ†æ
        
        Args:
            gene_target: ç›®æ ‡åŸºå› 
            focus_areas: å…³æ³¨é¢†åŸŸ ['function', 'pathways', 'diseases', 'drugs']
        
        Returns:
            BiologyAnalysisResultå¯¹è±¡
        """
        
        try:
            logger.info(f"å¼€å§‹ç”Ÿç‰©å­¦åˆ†æ: {gene_target}")
            start_time = datetime.now()
            
            # é»˜è®¤åˆ†ææ‰€æœ‰é¢†åŸŸ
            if focus_areas is None:
                focus_areas = ['function', 'pathways', 'diseases', 'drugs']
            
            # æ­¥éª¤1: æ”¶é›†æ–‡çŒ®æ•°æ®
            literature_data = await self._collect_literature_data(gene_target)
            
            # æ­¥éª¤2: åˆ†æä¸åŒé¢†åŸŸ
            analysis_results = {}
            
            if 'function' in focus_areas:
                analysis_results['function'] = await self._analyze_gene_function(
                    gene_target, literature_data
                )
            
            if 'pathways' in focus_areas:
                analysis_results['pathways'] = await self._analyze_pathways(
                    gene_target, literature_data
                )
            
            if 'diseases' in focus_areas:
                analysis_results['diseases'] = await self._analyze_disease_associations(
                    gene_target, literature_data
                )
            
            if 'drugs' in focus_areas:
                analysis_results['drugs'] = await self._analyze_drug_interactions(
                    gene_target, literature_data
                )
            
            # æ­¥éª¤3: ç»¼åˆåˆ†æ
            result = await self._synthesize_results(
                gene_target, literature_data, analysis_results
            )
            
            # è®°å½•ä½¿ç”¨æƒ…å†µ
            end_time = datetime.now()
            analysis_time = (end_time - start_time).total_seconds()
            
            logger.info(f"ç”Ÿç‰©å­¦åˆ†æå®Œæˆ: {gene_target} ({analysis_time:.1f}s)")
            
            return result
            
        except Exception as e:
            logger.error(f"ç”Ÿç‰©å­¦åˆ†æå¤±è´¥: {gene_target} - {str(e)}")
            raise
    
    async def _collect_literature_data(self, gene_target: str) -> Dict[str, Any]:
        """æ”¶é›†æ–‡çŒ®æ•°æ® - ä½¿ç”¨å·¥ä½œçš„æ£€ç´¢å™¨"""
        
        try:
            logger.info(f"æ”¶é›† {gene_target} çš„æ–‡çŒ®æ•°æ®...")
            
            # å®šä¹‰ä¸åŒç±»å‹çš„æœç´¢æŸ¥è¯¢
            search_queries = {
                'general': f"{gene_target} function",
                'pathways': f"{gene_target} pathway signaling",
                'diseases': f"{gene_target} disease cancer",
                'drugs': f"{gene_target} drug therapy treatment",
                'recent': f"{gene_target} 2023 2024"
            }
            
            literature_results = {}
            
            async with PubMedRetriever() as retriever:
                for query_type, query in search_queries.items():
                    # æ ¹æ®é…ç½®è°ƒæ•´æœç´¢æ•°é‡
                    max_results = self._get_literature_count_for_query(query_type)
                    
                    logger.info(f"æœç´¢ {query_type}: {query} (æœ€å¤š{max_results}ç¯‡)")
                    
                    try:
                        result = await retriever.search_literature(query, max_results)
                        literature_results[query_type] = {
                            'query': query,
                            'articles': result.articles,
                            'count': len(result.articles)
                        }
                        
                        logger.info(f"  âœ… {query_type}: è·å¾— {len(result.articles)} ç¯‡æ–‡çŒ®")
                        
                        # ç®€çŸ­å»¶è¿Ÿï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                        await asyncio.sleep(0.3)
                        
                    except Exception as e:
                        logger.warning(f"  âŒ {query_type} æœç´¢å¤±è´¥: {e}")
                        literature_results[query_type] = {
                            'query': query,
                            'articles': [],
                            'count': 0,
                            'error': str(e)
                        }
            
            # ç»Ÿè®¡æ€»æ–‡çŒ®æ•°
            total_articles = sum(
                data.get('count', 0) for data in literature_results.values()
            )
            
            logger.info(f"æ–‡çŒ®æ”¶é›†å®Œæˆ: æ€»å…± {total_articles} ç¯‡")
            
            return literature_results
            
        except Exception as e:
            logger.error(f"æ–‡çŒ®æ•°æ®æ”¶é›†å¤±è´¥: {e}")
            return {}
    
    def _get_literature_count_for_query(self, query_type: str) -> int:
        """æ ¹æ®é…ç½®å’ŒæŸ¥è¯¢ç±»å‹ç¡®å®šæ–‡çŒ®æ•°é‡"""
        
        base_counts = {
            "quick": {'general': 3, 'pathways': 2, 'diseases': 2, 'drugs': 2, 'recent': 1},
            "standard": {'general': 5, 'pathways': 4, 'diseases': 4, 'drugs': 4, 'recent': 3},
            "deep": {'general': 10, 'pathways': 8, 'diseases': 8, 'drugs': 8, 'recent': 5},
        }
        
        mode = getattr(self.config, 'mode', 'standard')
        mode_counts = base_counts.get(mode, base_counts['standard'])
        return mode_counts.get(query_type, 3)
    
    async def _analyze_gene_function(self, gene_target: str, literature_data: Dict) -> Dict[str, Any]:
        """åˆ†æåŸºå› åŠŸèƒ½ - åŸºäºæ–‡çŒ®å†…å®¹çš„ç®€åŒ–åˆ†æ"""
        
        try:
            general_articles = literature_data.get('general', {}).get('articles', [])
            
            if not general_articles:
                return {'functions': [], 'confidence': 0.0}
            
            # åŸºäºæ–‡çŒ®æ ‡é¢˜å’Œæ‘˜è¦çš„å…³é”®è¯åˆ†æ
            function_keywords = self._extract_function_keywords(general_articles)
            mechanisms = self._extract_mechanisms(general_articles)
            
            # ç®€åŒ–çš„åŠŸèƒ½åˆ†æ
            analysis_result = {
                "primary_functions": function_keywords[:5],  # å‰5ä¸ªåŠŸèƒ½
                "molecular_mechanisms": mechanisms,
                "cellular_localization": self._infer_localization(general_articles),
                "confidence_score": min(0.8, len(general_articles) * 0.1)
            }
            
            logger.info(f"åŸºå› åŠŸèƒ½åˆ†æå®Œæˆ: {len(function_keywords)} ä¸ªåŠŸèƒ½å…³é”®è¯")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"åŸºå› åŠŸèƒ½åˆ†æå¤±è´¥: {e}")
            return {'functions': [], 'confidence': 0.0}
    
    def _extract_function_keywords(self, articles: List[PubMedArticle]) -> List[str]:
        """ä»æ–‡çŒ®ä¸­æå–åŠŸèƒ½å…³é”®è¯"""
        
        function_terms = [
            'transcription', 'regulation', 'expression', 'binding', 'activation',
            'inhibition', 'signaling', 'metabolism', 'transport', 'catalysis',
            'repair', 'replication', 'translation', 'splicing', 'modification'
        ]
        
        found_functions = []
        
        for article in articles:
            text = (article.title + " " + article.abstract).lower()
            
            for term in function_terms:
                if term in text and term not in found_functions:
                    found_functions.append(term)
        
        return found_functions
    
    def _extract_mechanisms(self, articles: List[PubMedArticle]) -> str:
        """æå–åˆ†å­æœºåˆ¶æè¿°"""
        
        mechanism_keywords = ['mechanism', 'pathway', 'interaction', 'binding', 'regulation']
        
        mechanisms = []
        for article in articles[:3]:  # åªçœ‹å‰3ç¯‡
            title_lower = article.title.lower()
            abstract_lower = article.abstract.lower()
            
            for keyword in mechanism_keywords:
                if keyword in title_lower or keyword in abstract_lower:
                    # æå–åŒ…å«å…³é”®è¯çš„å¥å­ç‰‡æ®µ
                    if keyword in abstract_lower:
                        sentences = article.abstract.split('.')
                        for sentence in sentences:
                            if keyword in sentence.lower():
                                mechanisms.append(sentence.strip())
                                break
        
        return "; ".join(mechanisms[:2])  # æœ€å¤š2ä¸ªæœºåˆ¶æè¿°
    
    def _infer_localization(self, articles: List[PubMedArticle]) -> str:
        """æ¨æ–­ç»†èƒå®šä½"""
        
        localization_terms = {
            'nucleus': ['nucleus', 'nuclear', 'chromatin'],
            'cytoplasm': ['cytoplasm', 'cytoplasmic', 'cytosol'],
            'membrane': ['membrane', 'transmembrane', 'surface'],
            'mitochondria': ['mitochondria', 'mitochondrial'],
            'secreted': ['secreted', 'extracellular', 'plasma']
        }
        
        for article in articles[:3]:
            text = (article.title + " " + article.abstract).lower()
            
            for location, terms in localization_terms.items():
                if any(term in text for term in terms):
                    return location
        
        return "unknown"
    
    async def _analyze_pathways(self, gene_target: str, literature_data: Dict) -> Dict[str, Any]:
        """åˆ†æä¿¡å·é€šè·¯"""
        
        try:
            pathway_articles = literature_data.get('pathways', {}).get('articles', [])
            
            if not pathway_articles:
                return {'pathways': [], 'confidence': 0.0}
            
            # æå–é€šè·¯å…³é”®è¯
            pathway_keywords = self._extract_pathway_keywords(pathway_articles)
            interactions = self._extract_interactions(pathway_articles)
            
            analysis_result = {
                "major_pathways": pathway_keywords[:5],
                "pathway_roles": {pathway: "å‚ä¸è°ƒèŠ‚" for pathway in pathway_keywords[:3]},
                "key_interactions": interactions,
                "disease_relevance": "ä¸å¤šç§ç–¾ç—…å‘ç”Ÿå‘å±•ç›¸å…³",
                "confidence_score": min(0.8, len(pathway_articles) * 0.1)
            }
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"é€šè·¯åˆ†æå¤±è´¥: {e}")
            return {'pathways': [], 'confidence': 0.0}
    
    def _extract_pathway_keywords(self, articles: List[PubMedArticle]) -> List[str]:
        """æå–é€šè·¯å…³é”®è¯"""
        
        pathway_terms = [
            'p53', 'MAPK', 'PI3K', 'AKT', 'mTOR', 'Wnt', 'Notch', 'TGF-beta',
            'NF-kB', 'JAK-STAT', 'DNA repair', 'apoptosis', 'cell cycle'
        ]
        
        found_pathways = []
        
        for article in articles:
            text = (article.title + " " + article.abstract).lower()
            
            for pathway in pathway_terms:
                if pathway.lower() in text and pathway not in found_pathways:
                    found_pathways.append(pathway)
        
        return found_pathways
    
    def _extract_interactions(self, articles: List[PubMedArticle]) -> List[str]:
        """æå–ç›¸äº’ä½œç”¨åŸºå› /è›‹ç™½"""
        
        # å¸¸è§çš„åŸºå› åç§°æ¨¡å¼
        gene_patterns = ['p53', 'ATM', 'BRCA1', 'BRCA2', 'MDM2', 'p21', 'AKT', 'mTOR']
        
        interactions = []
        
        for article in articles[:3]:
            text = article.title + " " + article.abstract
            
            for gene in gene_patterns:
                if gene in text and gene not in interactions:
                    interactions.append(gene)
        
        return interactions[:5]  # æœ€å¤š5ä¸ªç›¸äº’ä½œç”¨
    
    async def _analyze_disease_associations(self, gene_target: str, literature_data: Dict) -> Dict[str, Any]:
        """åˆ†æç–¾ç—…å…³è”"""
        
        try:
            disease_articles = literature_data.get('diseases', {}).get('articles', [])
            
            if not disease_articles:
                return {'diseases': [], 'confidence': 0.0}
            
            diseases = self._extract_diseases(disease_articles)
            mutations = self._extract_mutations(disease_articles)
            
            analysis_result = {
                "associated_diseases": [
                    {"disease": disease, "mutation_type": "various", "clinical_significance": "ç ”ç©¶ä¸­"}
                    for disease in diseases
                ],
                "disease_mechanisms": "åŸºå› åŠŸèƒ½å¼‚å¸¸å¯¼è‡´ç–¾ç—…å‘ç”Ÿ",
                "biomarker_potential": "å…·æœ‰æ½œåœ¨çš„ç”Ÿç‰©æ ‡å¿—ç‰©ä»·å€¼",
                "confidence_score": min(0.9, len(disease_articles) * 0.15)
            }
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"ç–¾ç—…å…³è”åˆ†æå¤±è´¥: {e}")
            return {'diseases': [], 'confidence': 0.0}
    
    def _extract_diseases(self, articles: List[PubMedArticle]) -> List[str]:
        """æå–ç–¾ç—…åç§°"""
        
        disease_terms = [
            'cancer', 'tumor', 'carcinoma', 'lymphoma', 'leukemia', 'sarcoma',
            'diabetes', 'alzheimer', 'parkinson', 'heart disease', 'stroke'
        ]
        
        found_diseases = []
        
        for article in articles:
            text = (article.title + " " + article.abstract).lower()
            
            for disease in disease_terms:
                if disease in text and disease not in found_diseases:
                    found_diseases.append(disease)
        
        return found_diseases
    
    def _extract_mutations(self, articles: List[PubMedArticle]) -> List[str]:
        """æå–çªå˜ç±»å‹"""
        
        mutation_terms = ['mutation', 'deletion', 'insertion', 'polymorphism', 'variant']
        
        found_mutations = []
        
        for article in articles:
            text = (article.title + " " + article.abstract).lower()
            
            for mutation in mutation_terms:
                if mutation in text and mutation not in found_mutations:
                    found_mutations.append(mutation)
        
        return found_mutations
    
    async def _analyze_drug_interactions(self, gene_target: str, literature_data: Dict) -> Dict[str, Any]:
        """åˆ†æè¯ç‰©ç›¸äº’ä½œç”¨"""
        
        try:
            drug_articles = literature_data.get('drugs', {}).get('articles', [])
            
            if not drug_articles:
                return {'drugs': [], 'confidence': 0.0}
            
            drugs = self._extract_drugs(drug_articles)
            
            analysis_result = {
                "drug_interactions": [
                    {"drug": drug, "mechanism": "target modulation", "effect": "therapeutic potential"}
                    for drug in drugs
                ],
                "pharmacogenomics": "åŸºå› å˜å¼‚å¯èƒ½å½±å“è¯ç‰©ååº”",
                "personalized_medicine": "æœ‰æœ›ç”¨äºä¸ªæ€§åŒ–æ²»ç–—",
                "confidence_score": min(0.75, len(drug_articles) * 0.12)
            }
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"è¯ç‰©ç›¸äº’ä½œç”¨åˆ†æå¤±è´¥: {e}")
            return {'drugs': [], 'confidence': 0.0}
    
    def _extract_drugs(self, articles: List[PubMedArticle]) -> List[str]:
        """æå–è¯ç‰©åç§°"""
        
        drug_terms = [
            'chemotherapy', 'radiation', 'inhibitor', 'agonist', 'antagonist',
            'therapy', 'treatment', 'drug', 'compound', 'molecule'
        ]
        
        found_drugs = []
        
        for article in articles:
            text = (article.title + " " + article.abstract).lower()
            
            for drug in drug_terms:
                if drug in text and drug not in found_drugs:
                    found_drugs.append(drug)
        
        return found_drugs
    
    async def _synthesize_results(self, 
                                gene_target: str, 
                                literature_data: Dict, 
                                analysis_results: Dict) -> BiologyAnalysisResult:
        """ç»¼åˆåˆ†æç»“æœ"""
        
        try:
            # ç»Ÿè®¡æ–‡çŒ®æ•°é‡
            total_articles = sum(
                data.get('count', 0) for data in literature_data.values()
            )
            
            # æå–å…³é”®å‘ç°
            key_findings = []
            biological_functions = []
            pathways_involved = []
            disease_associations = []
            drug_interactions = []
            
            # ä»å„ä¸ªåˆ†æä¸­æå–ä¿¡æ¯
            if 'function' in analysis_results:
                func_data = analysis_results['function']
                biological_functions = func_data.get('primary_functions', [])
                
                key_findings.append({
                    'category': 'åŸºå› åŠŸèƒ½',
                    'content': func_data.get('molecular_mechanisms', ''),
                    'confidence': func_data.get('confidence_score', 0.0)
                })
            
            if 'pathways' in analysis_results:
                pathway_data = analysis_results['pathways']
                pathways_involved = pathway_data.get('major_pathways', [])
                
                key_findings.append({
                    'category': 'ä¿¡å·é€šè·¯',
                    'content': pathway_data.get('disease_relevance', ''),
                    'confidence': pathway_data.get('confidence_score', 0.0)
                })
            
            if 'diseases' in analysis_results:
                disease_data = analysis_results['diseases']
                disease_associations = disease_data.get('associated_diseases', [])
                
                key_findings.append({
                    'category': 'ç–¾ç—…å…³è”',
                    'content': disease_data.get('disease_mechanisms', ''),
                    'confidence': disease_data.get('confidence_score', 0.0)
                })
            
            if 'drugs' in analysis_results:
                drug_data = analysis_results['drugs']
                drug_interactions = drug_data.get('drug_interactions', [])
                
                key_findings.append({
                    'category': 'è¯ç‰©ç›¸äº’ä½œç”¨',
                    'content': drug_data.get('pharmacogenomics', ''),
                    'confidence': drug_data.get('confidence_score', 0.0)
                })
            
            # é€‰æ‹©å…³é”®æ–‡çŒ®
            highly_cited_papers = self._select_key_papers(literature_data, 'general')
            recent_discoveries = self._select_key_papers(literature_data, 'recent')
            
            # ç”Ÿæˆç®€åŒ–æ€»ç»“
            biological_summary = f"{gene_target}åŸºå› å‚ä¸{', '.join(biological_functions[:3])}ç­‰ç”Ÿç‰©å­¦è¿‡ç¨‹ï¼Œ"
            biological_summary += f"æ¶‰åŠ{', '.join(pathways_involved[:2])}ç­‰ä¿¡å·é€šè·¯ã€‚"
            
            clinical_relevance = f"ä¸{len(disease_associations)}ç§ç–¾ç—…ç›¸å…³ï¼Œ"
            clinical_relevance += f"å…·æœ‰{len(drug_interactions)}ç§æ½œåœ¨è¯ç‰©ç›¸äº’ä½œç”¨ã€‚"
            
            research_gaps = ["éœ€è¦æ›´å¤šåŠŸèƒ½éªŒè¯ç ”ç©¶", "ä¸´åºŠè½¬åŒ–ç ”ç©¶ä¸è¶³", "åˆ†å­æœºåˆ¶æœ‰å¾…æ·±å…¥"]
            
            # è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦
            confidence_scores = [finding.get('confidence', 0.0) for finding in key_findings]
            overall_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
            
            # ä¼°ç®—tokenä½¿ç”¨é‡
            token_usage = {
                "total_tokens": len(analysis_results) * 200,
                "analysis_tokens": len(analysis_results) * 150,
                "literature_tokens": total_articles * 50
            }
            
            return BiologyAnalysisResult(
                gene_target=gene_target,
                total_articles=total_articles,
                analyzed_articles=min(total_articles, 20),
                key_findings=key_findings,
                biological_functions=biological_functions,
                pathways_involved=pathways_involved,
                disease_associations=disease_associations,
                drug_interactions=drug_interactions,
                publication_trends={"trend": "increasing", "years": ["2022", "2023", "2024"]},
                research_hotspots=["å…ç–«æ²»ç–—", "ç²¾å‡†åŒ»å­¦", "åŸºå› ç¼–è¾‘"],
                highly_cited_papers=highly_cited_papers,
                recent_discoveries=recent_discoveries,
                biological_summary=biological_summary,
                clinical_relevance=clinical_relevance,
                research_gaps=research_gaps,
                confidence_score=overall_confidence,
                last_updated=datetime.now().isoformat(),
                config_used=asdict(self.config),
                token_usage=token_usage
            )
            
        except Exception as e:
            logger.error(f"ç»“æœç»¼åˆå¤±è´¥: {e}")
            raise
    
    def _select_key_papers(self, literature_data: Dict, data_type: str) -> List[Dict[str, str]]:
        """é€‰æ‹©å…³é”®æ–‡çŒ®"""
        
        articles = literature_data.get(data_type, {}).get('articles', [])
        
        key_papers = []
        for article in articles[:3]:  # é€‰æ‹©å‰3ç¯‡
            key_papers.append({
                'pmid': article.pmid,
                'title': article.title,
                'journal': article.journal,
                'url': article.url
            })
        
        return key_papers


# æµ‹è¯•å‡½æ•°
async def test_biology_expert():
    """æµ‹è¯•Biology Expert"""
    
    print("ğŸ§  æµ‹è¯•Biology Expert with Working PubMed Retriever")
    print("=" * 60)
    
    # ä½¿ç”¨å¿«é€Ÿé…ç½®è¿›è¡Œæµ‹è¯•
    config = ConfigManager.get_quick_config()
    expert = BiologyExpert(config)
    
    print(f"ä¸“å®¶ä¿¡æ¯:")
    print(f"  åç§°: {expert.name} v{expert.version}")
    print(f"  é…ç½®: {expert.config.mode}")
    print(f"  ä¸“ä¸šé¢†åŸŸ: {', '.join(expert.expertise)}")
    
    test_genes = ['BRCA1', 'TP53']
    
    for gene in test_genes:
        print(f"\n{'='*40}")
        print(f"ğŸ§¬ åˆ†æåŸºå› : {gene}")
        print(f"{'='*40}")
        
        try:
            result = await expert.analyze(gene, focus_areas=['function', 'diseases'])
            
            print(f"\nğŸ“Š åˆ†æç»“æœ:")
            print(f"  åŸºå› : {result.gene_target}")
            print(f"  æ–‡çŒ®æ€»æ•°: {result.total_articles}")
            print(f"  åˆ†ææ–‡çŒ®: {result.analyzed_articles}")
            print(f"  ç½®ä¿¡åº¦: {result.confidence_score:.2f}")
            
            print(f"\nğŸ”¬ ç”Ÿç‰©å­¦åŠŸèƒ½:")
            for func in result.biological_functions[:3]:
                print(f"    â€¢ {func}")
            
            print(f"\nğŸ¥ ç–¾ç—…å…³è”:")
            for disease in result.disease_associations[:3]:
                print(f"    â€¢ {disease.get('disease', 'Unknown')}")
            
            print(f"\nğŸ“ˆ å…³é”®å‘ç°:")
            for finding in result.key_findings:
                print(f"    â€¢ {finding['category']}: {finding['content'][:100]}...")
            
            print(f"\nğŸ“„ ä»£è¡¨æ€§æ–‡çŒ®:")
            for paper in result.highly_cited_papers[:2]:
                print(f"    â€¢ [{paper['pmid']}] {paper['title'][:80]}...")
            
            print(f"\nğŸ’¡ æ€»ç»“:")
            print(f"    {result.biological_summary}")
            
            print(f"\nğŸ¯ ä¸´åºŠç›¸å…³æ€§:")
            print(f"    {result.clinical_relevance}")
            
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
            logger.error(f"åŸºå› åˆ†æå¤±è´¥: {gene}", exc_info=True)


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_biology_expert())