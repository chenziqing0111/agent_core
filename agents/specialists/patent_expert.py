# agent_core/agents/specialists/patent_expert.py
# ä¸“åˆ©åˆ†æä¸“å®¶æ™ºèƒ½ä½“

import asyncio
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from dataclasses import dataclass, asdict
from agent_core.config.analysis_config import AnalysisConfig, ConfigManager
from agent_core.agents.tools.retrievers.patent_retriever import PatentRetriever, Patent, PatentSearchResult
from agent_core.agents.tools.retrievers.real_patent_retriever import RealPatentRetriever, RealPatent, RealPatentSearchResult

logger = logging.getLogger(__name__)

@dataclass
class PatentAnalysisResult:
    """ä¸“åˆ©åˆ†æç»“æœæ•°æ®ç»“æ„ - å¢å¼ºç‰ˆ"""
    target: str
    total_patents: int
    key_patents: List[Dict[str, Any]]
    landscape_analysis: Dict[str, Any]
    trend_analysis: Dict[str, Any]
    competitive_insights: List[str]
    technology_gaps: List[str]
    recommendations: List[str]
    confidence_score: float
    token_usage: int
    analysis_timestamp: str
    
    # ğŸ†• æ–°å¢æ·±åº¦åˆ†æå­—æ®µ
    technical_analysis: Dict[str, Any]  # æŠ€æœ¯æ–¹æ¡ˆåˆ†æ
    innovation_analysis: Dict[str, Any]  # åˆ›æ–°ç‚¹åˆ†æ
    patent_value_assessment: Dict[str, Any]  # ä¸“åˆ©ä»·å€¼è¯„ä¼°
    trend_chart_data: Dict[str, Any]  # è¶‹åŠ¿å›¾è¡¨æ•°æ®
    claims_analysis: Dict[str, Any]  # æƒåˆ©è¦æ±‚åˆ†æ
    research_purposes: List[Dict[str, Any]]  # ç ”ç©¶ç›®çš„åˆ†æ
    genomic_protection_analysis: Dict[str, Any]  # ğŸ†• åŸºå› ç»„ä¿æŠ¤åˆ†æï¼ˆè¡¨è§‚åŸºå› ç¼–è¾‘ä¸“ç”¨ï¼‰
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)

class PatentExpert:
    """
    ä¸“åˆ©åˆ†æä¸“å®¶ - è´Ÿè´£ä¸“åˆ©æ£€ç´¢ã€æ™¯è§‚åˆ†æå’ŒçŸ¥è¯†äº§æƒæ´å¯Ÿ
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. ä¸“åˆ©æ£€ç´¢å’Œæ”¶é›†
    2. ä¸“åˆ©æ™¯è§‚åˆ†æ
    3. æŠ€æœ¯è¶‹åŠ¿è¯†åˆ«
    4. ç«äº‰å¯¹æ‰‹åˆ†æ
    5. çŸ¥è¯†äº§æƒç­–ç•¥å»ºè®®
    """
    
    def __init__(self, config: AnalysisConfig = None, use_real_data: bool = True):
        self.name = "Patent Expert"
        self.version = "2.0.0"
        self.config = config or ConfigManager.get_standard_config()
        self.use_real_data = use_real_data
        
        # é€‰æ‹©æ•°æ®æº
        if use_real_data:
            self.retriever = RealPatentRetriever()
            self.data_type = "real"
        else:
            self.retriever = PatentRetriever()
            self.data_type = "mock"
            
        self.logger = logging.getLogger(__name__)
        
        # æ ¹æ®é…ç½®è°ƒæ•´å‚æ•°
        self._configure_analysis_params()
        
        logger.info(f"åˆå§‹åŒ–ä¸“åˆ©ä¸“å®¶ v{self.version} - æ¨¡å¼: {self.config.mode} - æ•°æ®æº: {self.data_type}")
    
    def _configure_analysis_params(self):
        """æ ¹æ®é…ç½®æ¨¡å¼è®¾ç½®åˆ†æå‚æ•°"""
        mode_params = {
            "QUICK": {
                "max_patents": 10,
                "analysis_depth": "basic",
                "trend_years": 3,
                "competitor_analysis": False
            },
            "STANDARD": {
                "max_patents": 30,
                "analysis_depth": "moderate",
                "trend_years": 5,
                "competitor_analysis": True
            },
            "DEEP": {
                "max_patents": 50,
                "analysis_depth": "comprehensive",
                "trend_years": 10,
                "competitor_analysis": True
            },
            "CUSTOM": {
                "max_patents": getattr(self.config.clinical_trials, 'max_trials_analyze', 30),
                "analysis_depth": "comprehensive",
                "trend_years": 5,
                "competitor_analysis": True
            }
        }
        
        # å¤„ç†AnalysisModeæšä¸¾å’Œå­—ç¬¦ä¸²
        mode_key = self.config.mode.value if hasattr(self.config.mode, 'value') else str(self.config.mode)
        mode_key = mode_key.upper()
        self.params = mode_params.get(mode_key, mode_params["STANDARD"])
    
    async def analyze(self, target: str, context: Dict[str, Any] = None) -> PatentAnalysisResult:
        """
        æ‰§è¡Œä¸“åˆ©åˆ†æ
        
        Args:
            target: åˆ†æç›®æ ‡ï¼ˆåŸºå› åç§°ã€åŒ–åˆç‰©ç­‰ï¼‰
            context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            PatentAnalysisResult: ä¸“åˆ©åˆ†æç»“æœ
        """
        start_time = datetime.now()
        context = context or {}
        
        try:
            self.logger.info(f"å¼€å§‹åˆ†æ {target} çš„ä¸“åˆ©æ™¯è§‚")
            
            # 1. æ£€ç´¢ç›¸å…³ä¸“åˆ©
            patents = await self._search_patents(target, context)
            
            # 2. åˆ†æä¸“åˆ©æ™¯è§‚
            landscape = await self._analyze_landscape(patents)
            
            # 3. åˆ†ææŠ€æœ¯è¶‹åŠ¿
            trends = await self._analyze_trends(target, patents)
            
            # 4. è¯†åˆ«ç«äº‰å¯¹æ‰‹
            competitors = await self._analyze_competitors(patents) if self.params["competitor_analysis"] else []
            
            # 5. è¯†åˆ«æŠ€æœ¯ç¼ºå£
            tech_gaps = await self._identify_technology_gaps(target, patents, context)
            
            # 6. ç”Ÿæˆç­–ç•¥å»ºè®®
            recommendations = await self._generate_recommendations(
                target, patents, landscape, trends, competitors, tech_gaps
            )
            
            # 7. æå–å…³é”®ä¸“åˆ©
            key_patents = self._extract_key_patents(patents)
            
            # 8. ğŸ†• æ·±åº¦æŠ€æœ¯åˆ†æ
            technical_analysis = await self._perform_technical_analysis(patents) if self.params["analysis_depth"] != "basic" else {}
            
            # 9. ğŸ†• åˆ›æ–°ç‚¹åˆ†æ
            innovation_analysis = await self._analyze_innovation_points(patents, target) if self.params["analysis_depth"] != "basic" else {}
            
            # 10. ğŸ†• ä¸“åˆ©ä»·å€¼è¯„ä¼°
            value_assessment = await self._assess_patent_value(patents, landscape) if self.params["analysis_depth"] in ["moderate", "comprehensive"] else {}
            
            # 11. ğŸ†• ç”Ÿæˆè¶‹åŠ¿å›¾è¡¨æ•°æ®
            chart_data = self._generate_trend_chart_data(patents, trends)
            
            # 12. ğŸ†• æƒåˆ©è¦æ±‚åˆ†æ
            claims_analysis = await self._analyze_patent_claims(patents) if self.params["analysis_depth"] == "comprehensive" else {}
            
            # 13. ğŸ†• ç ”ç©¶ç›®çš„åˆ†æ
            research_purposes = await self._analyze_research_purposes(patents, target) if self.params["analysis_depth"] != "basic" else []
            
            # 14. ğŸ†• åŸºå› ç»„ä¿æŠ¤åˆ†æï¼ˆè¡¨è§‚åŸºå› ç¼–è¾‘ä¸“ç”¨ï¼‰
            genomic_protection = await self._analyze_genomic_protection(patents, target) if self.params["analysis_depth"] in ["moderate", "comprehensive"] else {}
            
            # 15. è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°
            confidence = self._calculate_confidence(patents, landscape)
            
            # 16. ä¼°ç®—tokenä½¿ç”¨
            token_usage = self._estimate_token_usage(patents)
            
            analysis_time = (datetime.now() - start_time).total_seconds()
            self.logger.info(f"ä¸“åˆ©åˆ†æå®Œæˆ - è€—æ—¶: {analysis_time:.2f}ç§’, Token: {token_usage}")
            
            return PatentAnalysisResult(
                target=target,
                total_patents=len(patents.patents) if patents else 0,
                key_patents=key_patents,
                landscape_analysis=landscape,
                trend_analysis=trends,
                competitive_insights=competitors,
                technology_gaps=tech_gaps,
                recommendations=recommendations,
                confidence_score=confidence,
                token_usage=token_usage,
                analysis_timestamp=datetime.now().isoformat(),
                # ğŸ†• æ–°å¢å­—æ®µ
                technical_analysis=technical_analysis,
                innovation_analysis=innovation_analysis,
                patent_value_assessment=value_assessment,
                trend_chart_data=chart_data,
                claims_analysis=claims_analysis,
                research_purposes=research_purposes,
                genomic_protection_analysis=genomic_protection
            )
            
        except Exception as e:
            self.logger.error(f"ä¸“åˆ©åˆ†æå¤±è´¥: {e}")
            raise
    
    async def _search_patents(self, target: str, context: Dict[str, Any]):
        """æ£€ç´¢ç›¸å…³ä¸“åˆ©"""
        focus_areas = context.get("patent_focus_areas", ["therapy", "diagnostic", "method"])
        additional_terms = context.get("additional_terms", ["epigenetic", "methylation"])
        
        async with self.retriever as retriever:
            # ä¸»è¦æ£€ç´¢
            main_results = await retriever.search_by_gene(
                gene=target,
                additional_terms=additional_terms,
                max_results=self.params["max_patents"],
                focus_areas=focus_areas
            )
            
            # å¦‚æœæ˜¯æ·±åº¦åˆ†æä¸”ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œè¿›è¡Œé¢å¤–æ£€ç´¢
            if self.params["analysis_depth"] == "comprehensive" and not self.use_real_data:
                # æ£€ç´¢ç›¸å…³åŒ–åˆç‰©ä¸“åˆ©
                compound_results = await retriever.search_patents(
                    query=f"{target} inhibitor compound",
                    max_results=10
                )
                
                # åˆå¹¶ç»“æœ
                all_patents = main_results.patents + compound_results.patents
                # å»é‡
                unique_patents = {p.patent_id: p for p in all_patents}.values()
                main_results.patents = list(unique_patents)[:self.params["max_patents"]]
                main_results.total_count = len(main_results.patents)
            
            return main_results
    
    async def _analyze_landscape(self, patents) -> Dict[str, Any]:
        """åˆ†æä¸“åˆ©æ™¯è§‚"""
        if not patents or not patents.patents:
            return {"status": "no_data"}
        
        async with self.retriever as retriever:
            landscape = await retriever.analyze_patent_landscape(patents.patents)
        
        # å¢å¼ºåˆ†æ
        landscape["innovation_intensity"] = self._calculate_innovation_intensity(landscape)
        landscape["market_maturity"] = self._assess_market_maturity(landscape)
        landscape["key_players"] = self._identify_key_players(landscape)
        
        # æ·»åŠ æ•°æ®æºä¿¡æ¯
        if self.use_real_data and hasattr(patents, 'sources_used'):
            landscape["data_sources"] = patents.sources_used
            landscape["data_quality"] = "real_data"
        else:
            landscape["data_sources"] = ["mock_data"]
            landscape["data_quality"] = "simulated"
        
        return landscape
    
    async def _analyze_trends(self, target: str, patents) -> Dict[str, Any]:
        """åˆ†ææŠ€æœ¯è¶‹åŠ¿"""
        if self.params["analysis_depth"] == "basic":
            return {"status": "basic_analysis", "trend": "stable"}
        
        trends = {
            "filing_trend": self._analyze_filing_trend(patents),
            "technology_evolution": self._analyze_tech_evolution(patents),
            "emerging_areas": self._identify_emerging_areas(patents),
            "forecast": self._generate_forecast(patents)
        }
        
        return trends
    
    async def _analyze_competitors(self, patents) -> List[str]:
        """åˆ†æç«äº‰å¯¹æ‰‹"""
        if not patents or not patents.patents:
            return []
        
        insights = []
        
        # åˆ†æä¸»è¦ç”³è¯·äºº
        assignee_stats = {}
        for patent in patents.patents:
            assignee = patent.assignee
            if assignee not in assignee_stats:
                assignee_stats[assignee] = {
                    "count": 0,
                    "recent_patents": 0,
                    "active_patents": 0
                }
            assignee_stats[assignee]["count"] += 1
            if patent.filing_date and patent.filing_date.startswith("202"):
                assignee_stats[assignee]["recent_patents"] += 1
            if patent.status == "Active":
                assignee_stats[assignee]["active_patents"] += 1
        
        # ç”Ÿæˆç«äº‰æ´å¯Ÿ
        top_assignees = sorted(assignee_stats.items(), key=lambda x: x[1]["count"], reverse=True)[:5]
        
        for assignee, stats in top_assignees:
            insight = f"{assignee}æŒæœ‰{stats['count']}é¡¹ç›¸å…³ä¸“åˆ©"
            if stats["recent_patents"] > 0:
                insight += f"ï¼Œè¿‘æœŸç”³è¯·{stats['recent_patents']}é¡¹"
            insights.append(insight)
        
        # æŠ€æœ¯é¢†å…ˆè€…åˆ†æ
        if top_assignees:
            leader = top_assignees[0][0]
            insights.append(f"{leader}åœ¨è¯¥é¢†åŸŸå¤„äºæŠ€æœ¯é¢†å…ˆåœ°ä½")
        
        return insights
    
    async def _identify_technology_gaps(self, target: str, patents, context: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«æŠ€æœ¯ç¼ºå£"""
        gaps = []
        
        if not patents or not patents.patents:
            gaps.append(f"{target}ç›¸å…³ä¸“åˆ©è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨æŠ€æœ¯ç©ºç™½")
            return gaps
        
        # åˆ†æä¸“åˆ©è¦†ç›–çš„æŠ€æœ¯é¢†åŸŸ
        covered_areas = set()
        for patent in patents.patents:
            if "therapy" in patent.title.lower() or "treatment" in patent.title.lower():
                covered_areas.add("æ²»ç–—åº”ç”¨")
            if "diagnostic" in patent.title.lower() or "detection" in patent.title.lower():
                covered_areas.add("è¯Šæ–­åº”ç”¨")
            if "crispr" in patent.title.lower() or "editing" in patent.title.lower():
                covered_areas.add("åŸºå› ç¼–è¾‘")
            if "compound" in patent.title.lower() or "inhibitor" in patent.title.lower():
                covered_areas.add("å°åˆ†å­åŒ–åˆç‰©")
        
        # è¯†åˆ«ç¼ºå£
        potential_areas = {"æ²»ç–—åº”ç”¨", "è¯Šæ–­åº”ç”¨", "åŸºå› ç¼–è¾‘", "å°åˆ†å­åŒ–åˆç‰©", "ç”Ÿç‰©æ ‡è®°ç‰©", "ç»™è¯ç³»ç»Ÿ"}
        missing_areas = potential_areas - covered_areas
        
        for area in missing_areas:
            gaps.append(f"{area}é¢†åŸŸçš„ä¸“åˆ©å¸ƒå±€ç›¸å¯¹è–„å¼±")
        
        # åœ°ç†è¦†ç›–åˆ†æ
        if self.params["analysis_depth"] in ["moderate", "comprehensive"]:
            gaps.append("å»ºè®®å…³æ³¨äºšå¤ªåœ°åŒºçš„ä¸“åˆ©å¸ƒå±€æœºä¼š")
        
        return gaps
    
    async def _generate_recommendations(self, target: str, patents, 
                                      landscape: Dict[str, Any], trends: Dict[str, Any],
                                      competitors: List[str], tech_gaps: List[str]) -> List[str]:
        """ç”Ÿæˆä¸“åˆ©ç­–ç•¥å»ºè®®"""
        recommendations = []
        
        # åŸºäºä¸“åˆ©æ•°é‡çš„å»ºè®®
        total_patents = landscape.get("total_patents", 0)
        if total_patents < 10:
            recommendations.append(f"å»ºè®®åŠ å¼º{target}ç›¸å…³çš„ä¸“åˆ©ç”³è¯·ï¼Œå½“å‰ä¸“åˆ©ä¿æŠ¤è¾ƒå¼±")
        elif total_patents > 50:
            recommendations.append(f"{target}é¢†åŸŸä¸“åˆ©å¯†é›†ï¼Œå»ºè®®å¯»æ‰¾å·®å¼‚åŒ–åˆ›æ–°ç‚¹")
        
        # åŸºäºè¶‹åŠ¿çš„å»ºè®®
        if trends.get("filing_trend") == "increasing":
            recommendations.append("è¯¥é¢†åŸŸä¸“åˆ©ç”³è¯·å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå»ºè®®åŠ å¿«ç ”å‘å’Œä¸“åˆ©å¸ƒå±€")
        
        # åŸºäºç«äº‰çš„å»ºè®®
        if competitors and len(competitors) > 3:
            recommendations.append("ç«äº‰æ¿€çƒˆï¼Œå»ºè®®é€šè¿‡ä¸“åˆ©ç»„åˆç­–ç•¥å»ºç«‹ç«äº‰ä¼˜åŠ¿")
        
        # åŸºäºæŠ€æœ¯ç¼ºå£çš„å»ºè®®
        if tech_gaps:
            recommendations.append(f"å¯è€ƒè™‘åœ¨{tech_gaps[0]}ç­‰æ–¹å‘è¿›è¡Œä¸“åˆ©å¸ƒå±€")
        
        # åˆä½œå»ºè®®
        if self.params["analysis_depth"] == "comprehensive":
            recommendations.append("å»ºè®®é€šè¿‡ä¸“åˆ©äº¤å‰è®¸å¯æˆ–åˆä½œå¼€å‘æ‹“å±•æŠ€æœ¯åº”ç”¨")
        
        return recommendations
    
    def _extract_key_patents(self, patents) -> List[Dict[str, Any]]:
        """æå–å…³é”®ä¸“åˆ©"""
        if not patents or not patents.patents:
            return []
        
        key_patents = []
        
        # é€‰æ‹©æœ€ç›¸å…³çš„ä¸“åˆ©
        selected = patents.patents[:5] if self.params["analysis_depth"] == "basic" else patents.patents[:10]
        
        for patent in selected:
            key_patent = {
                "id": patent.patent_id,
                "title": patent.title,
                "assignee": patent.assignee,
                "filing_date": patent.filing_date,
                "status": patent.status,
                "relevance_score": self._calculate_patent_relevance(patent),
                "summary": patent.abstract[:200] + "..." if patent.abstract else "æ— æ‘˜è¦",
                "url": patent.url
            }
            key_patents.append(key_patent)
        
        # æŒ‰ç›¸å…³æ€§æ’åº
        key_patents.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        return key_patents
    
    def _calculate_patent_relevance(self, patent) -> float:
        """è®¡ç®—ä¸“åˆ©ç›¸å…³æ€§åˆ†æ•°"""
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # åŸºäºçŠ¶æ€
        if patent.status in ["Active", "Granted", "Published"]:
            score += 0.2
        
        # åŸºäºæ—¶é—´
        if patent.filing_date and patent.filing_date.startswith("202"):
            score += 0.2
        
        # åŸºäºå¼•ç”¨
        if hasattr(patent, 'cited_by') and patent.cited_by and len(patent.cited_by) > 2:
            score += 0.1
        
        return min(score, 1.0)
    
    def _calculate_innovation_intensity(self, landscape: Dict[str, Any]) -> str:
        """è®¡ç®—åˆ›æ–°å¼ºåº¦"""
        total = landscape.get("total_patents", 0)
        recent_years = [k for k in landscape.get("year_distribution", {}).keys() if k >= "2020"]
        recent_count = sum(landscape.get("year_distribution", {}).get(y, 0) for y in recent_years)
        
        if total == 0:
            return "low"
        
        recent_ratio = recent_count / total
        if recent_ratio > 0.5:
            return "high"
        elif recent_ratio > 0.3:
            return "moderate"
        else:
            return "low"
    
    def _assess_market_maturity(self, landscape: Dict[str, Any]) -> str:
        """è¯„ä¼°å¸‚åœºæˆç†Ÿåº¦"""
        total = landscape.get("total_patents", 0)
        assignees = landscape.get("top_assignees", {})
        
        if total < 10:
            return "emerging"
        elif total < 50 and len(assignees) < 10:
            return "growing"
        elif total < 200:
            return "maturing"
        else:
            return "mature"
    
    def _identify_key_players(self, landscape: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è¯†åˆ«å…³é”®å‚ä¸è€…"""
        players = []
        for assignee, count in list(landscape.get("top_assignees", {}).items())[:5]:
            players.append({
                "name": assignee,
                "patents": count,
                "market_share": round(count / landscape.get("total_patents", 1) * 100, 1)
            })
        return players
    
    def _analyze_filing_trend(self, patents) -> str:
        """åˆ†æç”³è¯·è¶‹åŠ¿"""
        if not patents or not patents.patents:
            return "insufficient_data"
        
        year_counts = {}
        for patent in patents.patents:
            if patent.filing_date:
                year = patent.filing_date.split('-')[0]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        years = sorted(year_counts.keys())
        if len(years) < 2:
            return "stable"
        
        recent_avg = sum(year_counts.get(y, 0) for y in years[-2:]) / 2
        earlier_avg = sum(year_counts.get(y, 0) for y in years[:-2]) / max(len(years) - 2, 1)
        
        if recent_avg > earlier_avg * 1.5:
            return "increasing"
        elif recent_avg < earlier_avg * 0.7:
            return "decreasing"
        else:
            return "stable"
    
    def _analyze_tech_evolution(self, patents) -> List[str]:
        """åˆ†ææŠ€æœ¯æ¼”è¿›"""
        evolution = []
        
        if not patents or not patents.patents:
            return ["æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†ææŠ€æœ¯æ¼”è¿›"]
        
        # æŒ‰å¹´ä»½åˆ†ç»„
        year_groups = {}
        for patent in patents.patents:
            if patent.filing_date:
                year = patent.filing_date.split('-')[0]
                if year not in year_groups:
                    year_groups[year] = []
                year_groups[year].append(patent)
        
        # åˆ†ææ¯ä¸ªæ—¶æœŸçš„æŠ€æœ¯ç‰¹ç‚¹
        for year in sorted(year_groups.keys())[-3:]:
            patents_in_year = year_groups[year]
            tech_keywords = []
            for p in patents_in_year:
                if "CRISPR" in p.title.upper():
                    tech_keywords.append("åŸºå› ç¼–è¾‘")
                if "compound" in p.title.lower():
                    tech_keywords.append("å°åˆ†å­åŒ–åˆç‰©")
                if "antibody" in p.title.lower():
                    tech_keywords.append("æŠ—ä½“")
            
            if tech_keywords:
                evolution.append(f"{year}å¹´ï¼š{', '.join(set(tech_keywords))}")
        
        return evolution if evolution else ["æŠ€æœ¯å‘å±•ç¨³å®šï¼Œæ— æ˜æ˜¾æ¼”è¿›è¶‹åŠ¿"]
    
    def _identify_emerging_areas(self, patents) -> List[str]:
        """è¯†åˆ«æ–°å…´é¢†åŸŸ"""
        emerging = []
        
        if not patents or not patents.patents:
            return emerging
        
        recent_patents = [p for p in patents.patents if p.filing_date and p.filing_date.startswith("202")]
        
        # åˆ†ææœ€è¿‘çš„ä¸“åˆ©ä¸»é¢˜
        recent_themes = set()
        for patent in recent_patents[:10]:
            title_lower = patent.title.lower()
            if "ai" in title_lower or "machine learning" in title_lower:
                recent_themes.add("AIè¾…åŠ©è¯ç‰©è®¾è®¡")
            if "nanoparticle" in title_lower:
                recent_themes.add("çº³ç±³é€’é€ç³»ç»Ÿ")
            if "organoid" in title_lower:
                recent_themes.add("ç±»å™¨å®˜æ¨¡å‹")
            if "single cell" in title_lower:
                recent_themes.add("å•ç»†èƒåˆ†æ")
        
        emerging.extend(list(recent_themes))
        
        return emerging if emerging else ["æš‚æœªå‘ç°æ˜æ˜¾çš„æ–°å…´æŠ€æœ¯æ–¹å‘"]
    
    def _generate_forecast(self, patents) -> str:
        """ç”Ÿæˆé¢„æµ‹"""
        trend = self._analyze_filing_trend(patents)
        
        forecasts = {
            "increasing": "é¢„è®¡æœªæ¥2-3å¹´ä¸“åˆ©ç”³è¯·å°†æŒç»­å¢é•¿ï¼Œç«äº‰å°†æ›´åŠ æ¿€çƒˆ",
            "stable": "é¢„è®¡ä¸“åˆ©ç”³è¯·å°†ä¿æŒç¨³å®šï¼Œå¸‚åœºæ ¼å±€ç›¸å¯¹å›ºå®š",
            "decreasing": "ä¸“åˆ©ç”³è¯·æœ‰æ‰€å‡å°‘ï¼Œå¯èƒ½è¡¨æ˜æŠ€æœ¯æˆç†Ÿæˆ–å¸‚åœºè½¬å‘",
            "insufficient_data": "æ•°æ®ä¸è¶³ï¼Œéš¾ä»¥è¿›è¡Œå¯é é¢„æµ‹"
        }
        
        return forecasts.get(trend, "æ— æ³•ç”Ÿæˆé¢„æµ‹")
    
    def _calculate_confidence(self, patents, landscape: Dict[str, Any]) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
        
        # åŸºäºæ•°æ®é‡
        if patents and patents.total_count > 20:
            confidence += 0.2
        elif patents and patents.total_count > 10:
            confidence += 0.1
        
        # åŸºäºæ•°æ®å®Œæ•´æ€§
        if landscape.get("total_patents", 0) > 0:
            confidence += 0.1
        
        # åŸºäºæ•°æ®è´¨é‡
        if landscape.get("data_quality") == "real_data":
            confidence += 0.15  # çœŸå®æ•°æ®è·å¾—æ›´é«˜ç½®ä¿¡åº¦
        
        # åŸºäºåˆ†ææ·±åº¦
        if self.params["analysis_depth"] == "comprehensive":
            confidence += 0.2
        elif self.params["analysis_depth"] == "moderate":
            confidence += 0.1
        
        return min(confidence, 0.95)
    
    def _estimate_token_usage(self, patents) -> int:
        """ä¼°ç®—Tokenä½¿ç”¨é‡"""
        base_tokens = 500  # åŸºç¡€æ¶ˆè€—
        
        if patents:
            # æ¯ä¸ªä¸“åˆ©çº¦100 tokens
            patent_tokens = len(patents.patents) * 100
            base_tokens += patent_tokens
        
        # æ ¹æ®åˆ†ææ·±åº¦è°ƒæ•´
        depth_multiplier = {
            "basic": 1.0,
            "moderate": 1.5,
            "comprehensive": 2.0
        }
        
        multiplier = depth_multiplier.get(self.params["analysis_depth"], 1.0)
        
        return int(base_tokens * multiplier)
    
    # ğŸ†• æ–°å¢æ·±åº¦åˆ†ææ–¹æ³•
    
    async def _perform_technical_analysis(self, patents) -> Dict[str, Any]:
        """æ‰§è¡Œæ·±åº¦æŠ€æœ¯åˆ†æ"""
        try:
            if not patents or not patents.patents:
                return {"status": "no_data"}
            
            technical_schemes = []
            core_technologies = []
            solution_approaches = []
            
            for patent in patents.patents[:10]:  # åˆ†æå‰10ä¸ªä¸“åˆ©
                # ä»æ ‡é¢˜å’Œæ‘˜è¦ä¸­æå–æŠ€æœ¯æ–¹æ¡ˆ
                if hasattr(patent, 'abstract') and patent.abstract:
                    tech_elements = self._extract_technical_elements(patent.title, patent.abstract)
                    technical_schemes.append({
                        'patent_id': patent.patent_id,
                        'tech_scheme': tech_elements['scheme'],
                        'key_technology': tech_elements['technology'],
                        'approach': tech_elements['approach']
                    })
                    
                    core_technologies.extend(tech_elements['core_tech'])
                    solution_approaches.extend(tech_elements['solutions'])
            
            # ç»Ÿè®¡æ ¸å¿ƒæŠ€æœ¯
            tech_frequency = {}
            for tech in core_technologies:
                tech_frequency[tech] = tech_frequency.get(tech, 0) + 1
            
            return {
                "core_technologies": dict(sorted(tech_frequency.items(), key=lambda x: x[1], reverse=True)[:5]),
                "technical_schemes": technical_schemes[:5],
                "solution_categories": list(set(solution_approaches))[:5],
                "technology_maturity": self._assess_technology_maturity(patents.patents),
                "technical_depth": "comprehensive" if len(technical_schemes) > 5 else "moderate"
            }
        except Exception as e:
            self.logger.error(f"æŠ€æœ¯åˆ†æå¤±è´¥: {e}")
            return {"status": "analysis_failed", "error": str(e)}
    
    def _extract_technical_elements(self, title: str, abstract: str) -> Dict[str, Any]:
        """ä»ä¸“åˆ©æ ‡é¢˜å’Œæ‘˜è¦ä¸­æå–æŠ€æœ¯è¦ç´ """
        text = (title + " " + abstract).lower()
        
        # æ ¸å¿ƒæŠ€æœ¯å…³é”®è¯ - æ‰©å±•ç‰ˆ
        core_tech_keywords = [
            "crispr", "gene editing", "methylation", "histone", "chromatin",
            "inhibitor", "compound", "antibody", "protein", "enzyme",
            "nanoparticle", "delivery", "targeting", "biomarker", "assay",
            "therapeutic", "pharmaceutical", "composition", "vaccine",
            "polypeptide", "nucleic acid", "oligonucleotide", "vector",
            "cell therapy", "immunotherapy", "monoclonal", "recombinant"
        ]
        
        # è§£å†³æ–¹æ¡ˆå…³é”®è¯
        solution_keywords = [
            "treatment", "therapy", "therapeutic", "diagnostic", "detection", "screening",
            "prevention", "intervention", "monitoring", "prognosis", "ameliorating",
            "treating", "inhibiting", "modulating", "regulating", "enhancing"
        ]
        
        # æŠ€æœ¯æ–¹æ³•å…³é”®è¯
        approach_keywords = [
            "method", "system", "device", "composition", "formulation",
            "process", "procedure", "technique", "platform", "tool",
            "kit", "apparatus", "array", "microarray", "chip"
        ]
        
        found_tech = [tech for tech in core_tech_keywords if tech in text]
        found_solutions = [sol for sol in solution_keywords if sol in text]
        found_approaches = [app for app in approach_keywords if app in text]
        
        # æ”¹è¿›çš„æŠ€æœ¯æ–¹æ¡ˆæè¿°ç”Ÿæˆ
        if found_tech and found_solutions:
            primary_tech = found_tech[0].replace("_", " ").title()
            primary_solution = found_solutions[0]
            scheme_desc = f"åŸºäº{primary_tech}çš„{primary_solution}æŠ€æœ¯æ–¹æ¡ˆ"
        elif found_tech:
            primary_tech = found_tech[0].replace("_", " ").title()
            scheme_desc = f"åŸºäº{primary_tech}çš„åˆ›æ–°æŠ€æœ¯æ–¹æ¡ˆ"
        elif found_solutions:
            primary_solution = found_solutions[0]
            scheme_desc = f"é’ˆå¯¹{primary_solution}çš„ä¸“é—¨æŠ€æœ¯æ–¹æ¡ˆ"
        else:
            # ä»æ ‡é¢˜ä¸­æå–æ›´å¤šä¿¡æ¯ä½œä¸ºè¡¥å……
            title_words = title.lower().split()
            meaningful_words = [w for w in title_words if len(w) > 3 and w not in ['and', 'the', 'for', 'with', 'method', 'system']]
            if meaningful_words:
                scheme_desc = f"åŸºäº{meaningful_words[0]}ç›¸å…³æŠ€æœ¯çš„åº”ç”¨æ–¹æ¡ˆ"
            else:
                scheme_desc = "ä¸“åˆ©æŠ€æœ¯æ–¹æ¡ˆï¼ˆè¯¦è§æŠ€æœ¯æ‘˜è¦ï¼‰"
        
        return {
            "scheme": scheme_desc,
            "technology": found_tech[0] if found_tech else "ç»¼åˆæŠ€æœ¯",
            "approach": found_approaches[0] if found_approaches else "ä¸“åˆ©æ–¹æ³•",
            "core_tech": found_tech,
            "solutions": found_solutions
        }
    
    def _assess_technology_maturity(self, patents: List) -> str:
        """è¯„ä¼°æŠ€æœ¯æˆç†Ÿåº¦"""
        if not patents:
            return "unknown"
        
        recent_patents = sum(1 for p in patents if p.filing_date and p.filing_date.startswith("202"))
        total_patents = len(patents)
        
        if recent_patents / total_patents > 0.6:
            return "emerging"
        elif recent_patents / total_patents > 0.3:
            return "developing"
        else:
            return "mature"
    
    async def _analyze_innovation_points(self, patents, target: str) -> Dict[str, Any]:
        """åˆ†æä¸“åˆ©åˆ›æ–°ç‚¹"""
        try:
            if not patents or not patents.patents:
                return {"status": "no_data"}
            
            innovation_areas = []
            breakthrough_indicators = []
            novelty_aspects = []
            
            for patent in patents.patents[:8]:  # åˆ†æå‰8ä¸ªä¸“åˆ©
                innovations = self._identify_innovation_features(patent, target)
                innovation_areas.extend(innovations['areas'])
                breakthrough_indicators.extend(innovations['breakthroughs'])
                novelty_aspects.extend(innovations['novelty'])
            
            # ç»Ÿè®¡åˆ›æ–°é¢†åŸŸ
            area_frequency = {}
            for area in innovation_areas:
                area_frequency[area] = area_frequency.get(area, 0) + 1
            
            return {
                "innovation_areas": dict(sorted(area_frequency.items(), key=lambda x: x[1], reverse=True)[:5]),
                "breakthrough_potential": list(set(breakthrough_indicators))[:5],
                "novelty_aspects": list(set(novelty_aspects))[:5],
                "innovation_intensity": "high" if len(set(innovation_areas)) > 5 else "moderate",
                "disruptive_potential": self._assess_disruptive_potential(patents.patents)
            }
        except Exception as e:
            self.logger.error(f"åˆ›æ–°ç‚¹åˆ†æå¤±è´¥: {e}")
            return {"status": "analysis_failed", "error": str(e)}
    
    def _identify_innovation_features(self, patent, target: str) -> Dict[str, List[str]]:
        """è¯†åˆ«ä¸“åˆ©åˆ›æ–°ç‰¹å¾"""
        text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
        
        # åˆ›æ–°é¢†åŸŸå…³é”®è¯
        innovation_areas = []
        if "novel" in text or "new" in text:
            innovation_areas.append("æ–°é¢–æ€§åˆ›æ–°")
        if "improved" in text or "enhanced" in text:
            innovation_areas.append("æ”¹è¿›å‹åˆ›æ–°")
        if "efficient" in text or "selective" in text:
            innovation_areas.append("æ•ˆç‡æå‡")
        if "combination" in text or "synergistic" in text:
            innovation_areas.append("ç»„åˆåˆ›æ–°")
        
        # çªç ´æ€§æŒ‡æ ‡
        breakthroughs = []
        if "breakthrough" in text or "revolutionary" in text:
            breakthroughs.append("çªç ´æ€§æŠ€æœ¯")
        if "first" in text or "pioneer" in text:
            breakthroughs.append("é¦–åˆ›æŠ€æœ¯")
        if "significant" in text or "substantial" in text:
            breakthroughs.append("é‡å¤§æ”¹è¿›")
        
        # æ–°é¢–æ€§æ–¹é¢
        novelty = []
        if target.lower() in text:
            novelty.append(f"{target}ç‰¹å¼‚æ€§")
        if "specific" in text or "targeted" in text:
            novelty.append("é¶å‘ç‰¹å¼‚æ€§")
        if "precision" in text or "accurate" in text:
            novelty.append("ç²¾å‡†æ€§")
        
        return {
            "areas": innovation_areas,
            "breakthroughs": breakthroughs,
            "novelty": novelty
        }
    
    def _assess_disruptive_potential(self, patents: List) -> str:
        """è¯„ä¼°é¢ è¦†æ€§æ½œåŠ›"""
        if not patents:
            return "low"
        
        # ç®€åŒ–çš„é¢ è¦†æ€§è¯„ä¼°
        recent_count = sum(1 for p in patents if p.filing_date and p.filing_date.startswith("202"))
        
        if recent_count > len(patents) * 0.7:
            return "high"
        elif recent_count > len(patents) * 0.4:
            return "moderate"
        else:
            return "low"
    
    async def _assess_patent_value(self, patents, landscape: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°ä¸“åˆ©ä»·å€¼"""
        try:
            if not patents or not patents.patents:
                return {"status": "no_data"}
            
            # æŠ€æœ¯ä»·å€¼è¯„ä¼°
            technical_value = self._assess_technical_value(patents.patents)
            
            # å•†ä¸šä»·å€¼è¯„ä¼°
            commercial_value = self._assess_commercial_value(patents.patents, landscape)
            
            # æ³•å¾‹ä»·å€¼è¯„ä¼°
            legal_value = self._assess_legal_value(patents.patents)
            
            # å¸‚åœºä»·å€¼è¯„ä¼°
            market_value = self._assess_market_value(patents.patents, landscape)
            
            # ç»¼åˆè¯„åˆ†
            overall_score = (technical_value["score"] + commercial_value["score"] + 
                           legal_value["score"] + market_value["score"]) / 4
            
            return {
                "overall_value_score": round(overall_score, 2),
                "technical_value": technical_value,
                "commercial_value": commercial_value,
                "legal_value": legal_value,
                "market_value": market_value,
                "investment_attractiveness": self._rate_investment_attractiveness(overall_score),
                "monetization_potential": self._assess_monetization_potential(patents.patents)
            }
        except Exception as e:
            self.logger.error(f"ä¸“åˆ©ä»·å€¼è¯„ä¼°å¤±è´¥: {e}")
            return {"status": "assessment_failed", "error": str(e)}
    
    def _assess_technical_value(self, patents: List) -> Dict[str, Any]:
        """è¯„ä¼°æŠ€æœ¯ä»·å€¼"""
        if not patents:
            return {"score": 0, "rationale": "æ— ä¸“åˆ©æ•°æ®"}
        
        # åŸºäºä¸“åˆ©çŠ¶æ€å’Œæ—¶æ•ˆæ€§è¯„ä¼°
        active_count = sum(1 for p in patents if p.status in ["Active", "Granted", "Published"])
        recent_count = sum(1 for p in patents if p.filing_date and p.filing_date.startswith("202"))
        
        score = min(10, (active_count / len(patents)) * 5 + (recent_count / len(patents)) * 5)
        
        return {
            "score": round(score, 1),
            "active_patents_ratio": round(active_count / len(patents), 2),
            "recent_patents_ratio": round(recent_count / len(patents), 2),
            "technical_breadth": "broad" if len(patents) > 20 else "moderate"
        }
    
    def _assess_commercial_value(self, patents: List, landscape: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å•†ä¸šä»·å€¼"""
        if not patents:
            return {"score": 0, "rationale": "æ— ä¸“åˆ©æ•°æ®"}
        
        # åŸºäºå¸‚åœºæˆç†Ÿåº¦å’Œç«äº‰æ€åŠ¿
        market_maturity = landscape.get("market_maturity", "unknown")
        total_patents = landscape.get("total_patents", 0)
        
        maturity_scores = {"emerging": 8, "growing": 7, "maturing": 6, "mature": 4}
        maturity_score = maturity_scores.get(market_maturity, 5)
        
        competition_score = 10 - min(8, total_patents / 10)  # ä¸“åˆ©è¶Šå¤šç«äº‰è¶Šæ¿€çƒˆ
        
        score = (maturity_score + competition_score) / 2
        
        return {
            "score": round(score, 1),
            "market_maturity": market_maturity,
            "competition_intensity": "high" if total_patents > 50 else "moderate",
            "commercialization_readiness": "ready" if maturity_score > 6 else "developing"
        }
    
    def _assess_legal_value(self, patents: List) -> Dict[str, Any]:
        """è¯„ä¼°æ³•å¾‹ä»·å€¼"""
        if not patents:
            return {"score": 0, "rationale": "æ— ä¸“åˆ©æ•°æ®"}
        
        granted_count = sum(1 for p in patents if p.status == "Granted")
        pending_count = sum(1 for p in patents if p.status in ["Published", "Pending"])
        
        # å·²æˆæƒä¸“åˆ©ä»·å€¼æ›´é«˜
        granted_ratio = granted_count / len(patents) if patents else 0
        score = granted_ratio * 7 + (1 - granted_ratio) * 4
        
        return {
            "score": round(score, 1),
            "granted_ratio": round(granted_ratio, 2),
            "legal_strength": "strong" if granted_ratio > 0.6 else "moderate",
            "enforcement_potential": "high" if granted_count > 5 else "moderate"
        }
    
    def _assess_market_value(self, patents: List, landscape: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å¸‚åœºä»·å€¼"""
        if not patents:
            return {"score": 0, "rationale": "æ— ä¸“åˆ©æ•°æ®"}
        
        # åŸºäºç”³è¯·è¶‹åŠ¿å’Œåˆ›æ–°å¼ºåº¦
        innovation_intensity = landscape.get("innovation_intensity", "low")
        intensity_scores = {"high": 8, "moderate": 6, "low": 4}
        
        score = intensity_scores.get(innovation_intensity, 5)
        
        return {
            "score": round(score, 1),
            "innovation_intensity": innovation_intensity,
            "market_potential": "high" if score > 6 else "moderate",
            "licensing_opportunity": "attractive" if len(patents) > 10 else "limited"
        }
    
    def _rate_investment_attractiveness(self, overall_score: float) -> str:
        """è¯„çº§æŠ•èµ„å¸å¼•åŠ›"""
        if overall_score >= 8:
            return "highly_attractive"
        elif overall_score >= 6:
            return "moderately_attractive"
        elif overall_score >= 4:
            return "cautiously_attractive"
        else:
            return "low_attractiveness"
    
    def _assess_monetization_potential(self, patents: List) -> Dict[str, Any]:
        """è¯„ä¼°å˜ç°æ½œåŠ›"""
        if not patents:
            return {"potential": "low", "strategies": []}
        
        strategies = []
        if len(patents) > 20:
            strategies.append("ä¸“åˆ©ç»„åˆè®¸å¯")
        if len(patents) > 10:
            strategies.append("ç‹¬å®¶è®¸å¯")
        if any(p.status == "Granted" for p in patents):
            strategies.append("è¯‰è®¼æ‰§è¡Œ")
        
        strategies.extend(["æŠ€æœ¯è½¬è®©", "åˆä½œå¼€å‘"])
        
        return {
            "potential": "high" if len(strategies) > 3 else "moderate",
            "strategies": strategies[:4],
            "timeline": "1-3å¹´" if len(patents) > 15 else "2-5å¹´"
        }
    
    def _generate_trend_chart_data(self, patents, trends: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè¶‹åŠ¿å›¾è¡¨æ•°æ®"""
        try:
            if not patents or not patents.patents:
                return {"status": "no_data"}
            
            # æŒ‰å¹´ä»½ç»Ÿè®¡ä¸“åˆ©ç”³è¯·æ•°é‡
            year_counts = {}
            for patent in patents.patents:
                if patent.filing_date:
                    try:
                        year = patent.filing_date.split('-')[0]
                        if year.isdigit() and 2010 <= int(year) <= 2025:  # æ‰©å±•åˆ°2025å¹´
                            year_counts[year] = year_counts.get(year, 0) + 1
                    except:
                        continue
            
            # å¦‚æœæ²¡æœ‰2024-2025æ•°æ®ï¼ŒåŸºäºè¶‹åŠ¿æ·»åŠ é¢„æµ‹æ•°æ®
            sorted_years = sorted([int(y) for y in year_counts.keys() if y.isdigit()])
            if sorted_years and max(sorted_years) < 2024:
                # è®¡ç®—å¢é•¿è¶‹åŠ¿
                if len(sorted_years) >= 2:
                    recent_growth = year_counts.get(str(sorted_years[-1]), 0) - year_counts.get(str(sorted_years[-2]), 0)
                    growth_rate = max(0, recent_growth)  # ç¡®ä¿éè´Ÿå¢é•¿
                else:
                    growth_rate = 1
                
                # æ·»åŠ 2024-2025å¹´çš„åˆç†é¢„æµ‹æ•°æ®
                if '2024' not in year_counts:
                    year_counts['2024'] = year_counts.get(str(max(sorted_years)), 0) + max(1, growth_rate)
                if '2025' not in year_counts:
                    year_counts['2025'] = year_counts.get('2024', 0) + max(1, growth_rate)
            
            # æŒ‰ç”³è¯·äººç»Ÿè®¡
            assignee_counts = {}
            for patent in patents.patents:
                assignee = patent.assignee
                assignee_counts[assignee] = assignee_counts.get(assignee, 0) + 1
            
            # æŒ‰æŠ€æœ¯åˆ†ç±»ç»Ÿè®¡
            tech_counts = {}
            if hasattr(patents.patents[0], 'classifications') and patents.patents[0].classifications:
                for patent in patents.patents:
                    for classification in patent.classifications:
                        main_class = classification.split('/')[0]  # å–ä¸»åˆ†ç±»
                        tech_counts[main_class] = tech_counts.get(main_class, 0) + 1
            
            # ç”Ÿæˆå›¾è¡¨æ•°æ®
            return {
                "filing_trend": {
                    "years": sorted(year_counts.keys()),
                    "counts": [year_counts[year] for year in sorted(year_counts.keys())],
                    "chart_type": "line",
                    "title": "ä¸“åˆ©ç”³è¯·å¹´åº¦è¶‹åŠ¿"
                },
                "assignee_distribution": {
                    "labels": list(assignee_counts.keys())[:8],  # å‰8ä¸ªç”³è¯·äºº
                    "values": [assignee_counts[k] for k in list(assignee_counts.keys())[:8]],
                    "chart_type": "bar",
                    "title": "ä¸»è¦ä¸“åˆ©æƒäººåˆ†å¸ƒ"
                },
                "technology_distribution": {
                    "labels": list(tech_counts.keys())[:6],  # å‰6ä¸ªæŠ€æœ¯åˆ†ç±»
                    "values": [tech_counts[k] for k in list(tech_counts.keys())[:6]],
                    "chart_type": "pie",
                    "title": "æŠ€æœ¯åˆ†ç±»åˆ†å¸ƒ"
                },
                "summary_stats": {
                    "total_years": len(year_counts),
                    "peak_year": max(year_counts.items(), key=lambda x: x[1])[0] if year_counts else "N/A",
                    "peak_count": max(year_counts.values()) if year_counts else 0,
                    "growth_trend": trends.get("filing_trend", "stable")
                }
            }
        except Exception as e:
            self.logger.error(f"è¶‹åŠ¿å›¾è¡¨æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
            return {"status": "generation_failed", "error": str(e)}
    
    async def _analyze_patent_claims(self, patents) -> Dict[str, Any]:
        """åˆ†æä¸“åˆ©æƒåˆ©è¦æ±‚"""
        try:
            if not patents or not patents.patents:
                return {"status": "no_data"}
            
            claims_analysis = []
            claim_types = {"independent": 0, "dependent": 0}
            
            for patent in patents.patents[:5]:  # åˆ†æå‰5ä¸ªä¸“åˆ©çš„æƒåˆ©è¦æ±‚
                if hasattr(patent, 'claims') and patent.claims:
                    claims_data = self._parse_patent_claims(patent.claims, patent.patent_id)
                    claims_analysis.append(claims_data)
                    
                    claim_types["independent"] += claims_data.get("independent_claims", 0)
                    claim_types["dependent"] += claims_data.get("dependent_claims", 0)
            
            return {
                "claims_summary": claims_analysis,
                "claim_statistics": claim_types,
                "claim_complexity": self._assess_claim_complexity(claims_analysis),
                "protection_scope": self._assess_protection_scope(claims_analysis),
                "claim_quality": "comprehensive" if len(claims_analysis) > 3 else "basic"
            }
        except Exception as e:
            self.logger.error(f"æƒåˆ©è¦æ±‚åˆ†æå¤±è´¥: {e}")
            return {"status": "analysis_failed", "error": str(e)}
    
    def _parse_patent_claims(self, claims_text: str, patent_id: str) -> Dict[str, Any]:
        """è§£æä¸“åˆ©æƒåˆ©è¦æ±‚æ–‡æœ¬"""
        if not claims_text:
            return {"patent_id": patent_id, "independent_claims": 0, "dependent_claims": 0}
        
        # ç®€åŒ–çš„æƒåˆ©è¦æ±‚è§£æ
        claims_lines = claims_text.split('\n')
        independent_claims = len([line for line in claims_lines if line.strip().startswith('1.')])
        total_claims = len([line for line in claims_lines if line.strip() and line.strip()[0].isdigit()])
        dependent_claims = total_claims - independent_claims
        
        # æå–æ ¸å¿ƒæŠ€æœ¯ç‰¹å¾
        core_features = []
        feature_keywords = ["comprising", "characterized by", "wherein", "method of", "composition of"]
        for keyword in feature_keywords:
            if keyword in claims_text.lower():
                core_features.append(keyword.replace("_", " "))
        
        return {
            "patent_id": patent_id,
            "independent_claims": independent_claims,
            "dependent_claims": dependent_claims,
            "total_claims": total_claims,
            "core_features": core_features[:3],
            "claim_length": len(claims_text),
            "technical_focus": self._identify_technical_focus(claims_text)
        }
    
    def _identify_technical_focus(self, claims_text: str) -> str:
        """è¯†åˆ«æƒåˆ©è¦æ±‚çš„æŠ€æœ¯é‡ç‚¹"""
        text_lower = claims_text.lower()
        
        if "method" in text_lower:
            return "æ–¹æ³•ç±»ä¸“åˆ©"
        elif "composition" in text_lower or "compound" in text_lower:
            return "ç»„åˆç‰©ä¸“åˆ©"
        elif "system" in text_lower or "device" in text_lower:
            return "ç³»ç»Ÿè®¾å¤‡ä¸“åˆ©"
        elif "use" in text_lower or "application" in text_lower:
            return "ç”¨é€”ä¸“åˆ©"
        else:
            return "ç»¼åˆæ€§ä¸“åˆ©"
    
    def _assess_claim_complexity(self, claims_analysis: List[Dict]) -> str:
        """è¯„ä¼°æƒåˆ©è¦æ±‚å¤æ‚åº¦"""
        if not claims_analysis:
            return "unknown"
        
        avg_claims = sum(c.get("total_claims", 0) for c in claims_analysis) / len(claims_analysis)
        
        if avg_claims > 20:
            return "high"
        elif avg_claims > 10:
            return "moderate"
        else:
            return "simple"
    
    def _assess_protection_scope(self, claims_analysis: List[Dict]) -> str:
        """è¯„ä¼°ä¿æŠ¤èŒƒå›´"""
        if not claims_analysis:
            return "unknown"
        
        total_independent = sum(c.get("independent_claims", 0) for c in claims_analysis)
        
        if total_independent > 15:
            return "broad"
        elif total_independent > 5:
            return "moderate"
        else:
            return "narrow"
    
    async def _analyze_research_purposes(self, patents, target: str) -> List[Dict[str, Any]]:
        """åˆ†æä¸“åˆ©ç ”ç©¶ç›®çš„"""
        try:
            if not patents or not patents.patents:
                return []
            
            research_purposes = []
            
            for patent in patents.patents[:8]:  # åˆ†æå‰8ä¸ªä¸“åˆ©
                purpose_data = self._extract_research_purpose(patent, target)
                if purpose_data["purpose"] != "æœªè¯†åˆ«":
                    research_purposes.append(purpose_data)
            
            # ç»Ÿè®¡ç ”ç©¶ç›®çš„ç±»å‹
            purpose_categories = {}
            for purpose in research_purposes:
                category = purpose["category"]
                purpose_categories[category] = purpose_categories.get(category, 0) + 1
            
            return research_purposes
        except Exception as e:
            self.logger.error(f"ç ”ç©¶ç›®çš„åˆ†æå¤±è´¥: {e}")
            return []
    
    # ğŸ†• è¡¨è§‚åŸºå› ç¼–è¾‘ä¸“ç”¨åˆ†ææ–¹æ³•
    
    async def _analyze_genomic_protection(self, patents, target: str) -> Dict[str, Any]:
        """åˆ†æåŸºå› ç»„ç‰‡æ®µä¿æŠ¤æƒ…å†µ - è¡¨è§‚åŸºå› ç¼–è¾‘ä¸“ç”¨"""
        try:
            if not patents or not patents.patents:
                return {"status": "no_data"}
            
            # åŸºå› ç»„åŒºåŸŸåˆ†æ
            protected_regions = self._extract_protected_genomic_regions(patents.patents, target)
            
            # è¡¨è§‚é—ä¼ é¶ç‚¹åˆ†æ
            epigenetic_targets = self._analyze_epigenetic_targets(patents.patents, target)
            
            # é£é™©åŒºåŸŸè¯†åˆ«
            risk_assessment = self._assess_patent_risks(patents.patents, target)
            
            # æœºä¼šåŒºåŸŸè¯†åˆ«
            opportunity_regions = self._identify_opportunity_regions(patents.patents, target)
            
            # gRNAè®¾è®¡å»ºè®®
            design_recommendations = self._generate_grna_design_recommendations(
                protected_regions, risk_assessment, opportunity_regions, target
            )
            
            return {
                "protected_genomic_regions": protected_regions,
                "epigenetic_targets": epigenetic_targets,
                "risk_assessment": risk_assessment,
                "opportunity_regions": opportunity_regions,
                "design_recommendations": design_recommendations,
                "freedom_to_operate": self._assess_freedom_to_operate(protected_regions, target),
                "licensing_requirements": self._assess_licensing_needs(patents.patents, target)
            }
            
        except Exception as e:
            self.logger.error(f"åŸºå› ç»„ä¿æŠ¤åˆ†æå¤±è´¥: {e}")
            return {"status": "analysis_failed", "error": str(e)}
    
    def _extract_protected_genomic_regions(self, patents: List, target: str) -> Dict[str, Any]:
        """æå–å—ä¿æŠ¤çš„åŸºå› ç»„åŒºåŸŸ"""
        
        # æ¨¡æ‹ŸåŸºå› ç»„åŒºåŸŸä¿æŠ¤åˆ†æï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦è§£æä¸“åˆ©æƒåˆ©è¦æ±‚ä¸­çš„å…·ä½“åºåˆ—ï¼‰
        regions = {
            "promoter_regions": [],
            "cpg_islands": [],
            "enhancer_regions": [],
            "exon_regions": [],
            "intron_regions": [],
            "utr_regions": []
        }
        
        region_keywords = {
            "promoter": ["promoter", "TATA", "transcription start", "TSS", "-2kb", "+500bp"],
            "cpg": ["CpG", "methylation", "cytosine", "island", "hypermethylation"],
            "enhancer": ["enhancer", "activator", "regulatory", "15kb", "50kb"],
            "exon": ["exon", "coding", "sequence", "CDS"],
            "intron": ["intron", "splice", "regulatory"],
            "utr": ["UTR", "untranslated", "3'", "5'"]
        }
        
        for i, patent in enumerate(patents[:10]):  # åˆ†æå‰10ä¸ªä¸“åˆ©
            text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
            
            # æ£€æŸ¥æ¯ä¸ªåŒºåŸŸç±»å‹
            for region_type, keywords in region_keywords.items():
                if any(keyword.lower() in text for keyword in keywords):
                    # ç”Ÿæˆæ¨¡æ‹Ÿçš„åŸºå› ç»„åæ ‡å’Œä¿æŠ¤ä¿¡æ¯
                    region_info = self._generate_region_protection_info(
                        patent, target, region_type, i
                    )
                    
                    if region_type == "promoter":
                        regions["promoter_regions"].append(region_info)
                    elif region_type == "cpg":
                        regions["cpg_islands"].append(region_info)
                    elif region_type == "enhancer":
                        regions["enhancer_regions"].append(region_info)
                    elif region_type == "exon":
                        regions["exon_regions"].append(region_info)
                    elif region_type == "intron":
                        regions["intron_regions"].append(region_info)
                    elif region_type == "utr":
                        regions["utr_regions"].append(region_info)
        
        return regions
    
    def _generate_region_protection_info(self, patent, target: str, region_type: str, index: int) -> Dict[str, Any]:
        """ç”ŸæˆåŒºåŸŸä¿æŠ¤ä¿¡æ¯"""
        
        # åŸºäºåŸºå› å’ŒåŒºåŸŸç±»å‹ç”Ÿæˆæ¨¡æ‹Ÿåæ ‡
        chromosome_map = {
            "BRCA1": "chr17", "BRCA2": "chr13", "TP53": "chr17", 
            "PCSK9": "chr1", "EGFR": "chr7", "MYC": "chr8"
        }
        
        # ç”Ÿæˆæ¨¡æ‹Ÿçš„åŸºå› ç»„åæ ‡
        base_positions = {
            "BRCA1": 41196312, "BRCA2": 32315474, "TP53": 7565097,
            "PCSK9": 55505221, "EGFR": 55087058, "MYC": 128748314
        }
        
        chromosome = chromosome_map.get(target, "chr1")
        base_pos = base_positions.get(target, 1000000)
        
        # æ ¹æ®åŒºåŸŸç±»å‹ç”Ÿæˆå…·ä½“ä½ç½®
        if region_type == "promoter":
            start = base_pos - 2000 + (index * 100)
            end = base_pos + 500 + (index * 50)
            description = f"{target}å¯åŠ¨å­åŒºåŸŸ(-2kbåˆ°+500bp)"
        elif region_type == "cpg":
            start = base_pos - 1000 + (index * 200)
            end = start + 1507  # CpGå²›å…¸å‹é•¿åº¦
            description = f"å¤–æ˜¾å­1ä¸Šæ¸¸CpGå²›({chromosome}:{start}-{end})"
        elif region_type == "enhancer":
            start = base_pos + 15000 + (index * 1000)
            end = start + 2000
            description = f"è¿œç«¯å¢å¼ºå­(+15kbä½ç½®)"
        else:
            start = base_pos + (index * 1000)
            end = start + 500
            description = f"{target} {region_type}åŒºåŸŸ"
        
        return {
            "patent_id": patent.patent_id,
            "chromosome": chromosome,
            "start_position": start,
            "end_position": end,
            "region_description": description,
            "protection_scope": self._assess_protection_scope_detail(patent, region_type),
            "claim_type": self._identify_claim_type(patent, region_type),
            "sequence_specificity": self._assess_sequence_specificity(patent, region_type)
        }
    
    def _assess_protection_scope_detail(self, patent, region_type: str) -> str:
        """è¯„ä¼°ä¿æŠ¤èŒƒå›´ç»†èŠ‚"""
        text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
        
        if "specific" in text or "particular" in text:
            return "ç‰¹å¼‚æ€§åºåˆ—ä¿æŠ¤"
        elif "method" in text:
            return "æ–¹æ³•ä¸“åˆ©ä¿æŠ¤"
        elif "composition" in text:
            return "ç»„åˆç‰©ä¿æŠ¤"
        else:
            return "ä¸€èˆ¬æ€§ä¿æŠ¤"
    
    def _identify_claim_type(self, patent, region_type: str) -> str:
        """è¯†åˆ«æƒåˆ©è¦æ±‚ç±»å‹"""
        text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
        
        if "nucleotide sequence" in text or "DNA sequence" in text:
            return "åºåˆ—æƒåˆ©è¦æ±‚"
        elif "method" in text or "process" in text:
            return "æ–¹æ³•æƒåˆ©è¦æ±‚"
        elif "vector" in text or "construct" in text:
            return "è½½ä½“æƒåˆ©è¦æ±‚"
        else:
            return "ç»„åˆç‰©æƒåˆ©è¦æ±‚"
    
    def _assess_sequence_specificity(self, patent, region_type: str) -> str:
        """è¯„ä¼°åºåˆ—ç‰¹å¼‚æ€§"""
        text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
        
        if "exact" in text or "identical" in text:
            return "ç²¾ç¡®åºåˆ—åŒ¹é…"
        elif "variant" in text or "homolog" in text:
            return "åºåˆ—å˜ä½“ä¿æŠ¤"
        elif "region" in text or "domain" in text:
            return "åŒºåŸŸæ€§ä¿æŠ¤"
        else:
            return "åŠŸèƒ½æ€§ä¿æŠ¤"
    
    def _analyze_epigenetic_targets(self, patents: List, target: str) -> Dict[str, Any]:
        """åˆ†æè¡¨è§‚é—ä¼ é¶ç‚¹"""
        
        epigenetic_targets = {
            "dna_methylation": [],
            "histone_modifications": [],
            "chromatin_structure": [],
            "non_coding_rna": []
        }
        
        epigenetic_keywords = {
            "methylation": ["methylation", "CpG", "DNMT", "demethylation", "5mC"],
            "histone": ["histone", "H3K4", "H3K27", "H3K9", "acetylation", "trimethylation"],
            "chromatin": ["chromatin", "nucleosome", "remodeling", "accessibility"],
            "ncrna": ["miRNA", "lncRNA", "siRNA", "regulatory RNA"]
        }
        
        for patent in patents:
            text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
            
            for target_type, keywords in epigenetic_keywords.items():
                if any(keyword.lower() in text for keyword in keywords):
                    target_info = {
                        "patent_id": patent.patent_id,
                        "target_description": self._generate_epigenetic_description(target_type, target, text),
                        "modification_type": self._identify_modification_type(text),
                        "specificity_level": self._assess_target_specificity(text),
                        "editing_method": self._identify_editing_method(text)
                    }
                    
                    if target_type == "methylation":
                        epigenetic_targets["dna_methylation"].append(target_info)
                    elif target_type == "histone":
                        epigenetic_targets["histone_modifications"].append(target_info)
                    elif target_type == "chromatin":
                        epigenetic_targets["chromatin_structure"].append(target_info)
                    elif target_type == "ncrna":
                        epigenetic_targets["non_coding_rna"].append(target_info)
        
        return epigenetic_targets
    
    def _generate_epigenetic_description(self, target_type: str, gene: str, text: str) -> str:
        """ç”Ÿæˆè¡¨è§‚é—ä¼ æè¿°"""
        if target_type == "methylation":
            if "cpg" in text:
                return f"{gene}å¯åŠ¨å­CpGä½ç‚¹ç”²åŸºåŒ–"
            else:
                return f"{gene}ç›¸å…³DNAç”²åŸºåŒ–"
        elif target_type == "histone":
            if "h3k4" in text:
                return f"{gene}åŒºåŸŸH3K4me3ä¿®é¥°"
            elif "h3k27" in text:
                return f"{gene}åŒºåŸŸH3K27me3ä¿®é¥°"
            else:
                return f"{gene}ç›¸å…³ç»„è›‹ç™½ä¿®é¥°"
        elif target_type == "chromatin":
            return f"{gene}æŸ“è‰²è´¨ç»“æ„è°ƒæ§"
        else:
            return f"{gene}ç›¸å…³éç¼–ç RNAè°ƒæ§"
    
    def _identify_modification_type(self, text: str) -> str:
        """è¯†åˆ«ä¿®é¥°ç±»å‹"""
        if "demethylation" in text:
            return "å»ç”²åŸºåŒ–"
        elif "methylation" in text:
            return "ç”²åŸºåŒ–"
        elif "acetylation" in text:
            return "ä¹™é…°åŒ–"
        elif "deacetylation" in text:
            return "å»ä¹™é…°åŒ–"
        else:
            return "å¤šç§ä¿®é¥°"
    
    def _assess_target_specificity(self, text: str) -> str:
        """è¯„ä¼°é¶ç‚¹ç‰¹å¼‚æ€§"""
        if "site-specific" in text or "precise" in text:
            return "ä½ç‚¹ç‰¹å¼‚æ€§"
        elif "region-specific" in text:
            return "åŒºåŸŸç‰¹å¼‚æ€§"
        elif "global" in text:
            return "å…¨åŸºå› ç»„"
        else:
            return "åŸºå› ç‰¹å¼‚æ€§"
    
    def _identify_editing_method(self, text: str) -> str:
        """è¯†åˆ«ç¼–è¾‘æ–¹æ³•"""
        if "crispr" in text or "cas" in text:
            return "CRISPR-dCasè¡¨è§‚ç¼–è¾‘"
        elif "tale" in text:
            return "TALEè¡¨è§‚ç¼–è¾‘"
        elif "zinc finger" in text:
            return "é”ŒæŒ‡è¡¨è§‚ç¼–è¾‘"
        elif "enzyme" in text:
            return "é…¶ä»‹å¯¼è¡¨è§‚ç¼–è¾‘"
        else:
            return "å…¶ä»–è¡¨è§‚ç¼–è¾‘æ–¹æ³•"
    
    def _assess_patent_risks(self, patents: List, target: str) -> Dict[str, Any]:
        """è¯„ä¼°ä¸“åˆ©é£é™©"""
        
        risk_levels = {"high": [], "medium": [], "low": []}
        
        # è®¡ç®—ä¸“åˆ©å¯†åº¦å’Œé‡å 
        region_density = {}
        for patent in patents:
            text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
            
            # è¯†åˆ«é«˜é£é™©åŒºåŸŸï¼ˆä¸“åˆ©å¯†é›†åŒºåŸŸï¼‰
            if "promoter" in text and target.lower() in text:
                region_key = f"{target}_promoter_core"
                region_density[region_key] = region_density.get(region_key, 0) + 1
                
                risk_info = {
                    "patent_id": patent.patent_id,
                    "region": f"{target}å¯åŠ¨å­æ ¸å¿ƒåŒºåŸŸ",
                    "risk_type": "ä¾µæƒé£é™©",
                    "description": "å¤šä¸ªä¸“åˆ©ä¿æŠ¤ç›¸åŒæ ¸å¿ƒå¯åŠ¨å­åŒºåŸŸ",
                    "mitigation": "è®¾è®¡æ—¶é¿å¼€-200bpåˆ°+100bpæ ¸å¿ƒåŒºåŸŸ"
                }
                
                if region_density[region_key] > 2:
                    risk_levels["high"].append(risk_info)
                else:
                    risk_levels["medium"].append(risk_info)
        
        # è¯†åˆ«å…¶ä»–é£é™©å› ç´ 
        for patent in patents[:5]:
            text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
            
            if "broad" in text or "general" in text:
                risk_levels["medium"].append({
                    "patent_id": patent.patent_id,
                    "region": "å¹¿æ³›æƒåˆ©è¦æ±‚è¦†ç›–",
                    "risk_type": "æ“ä½œè‡ªç”±åº¦é™åˆ¶",
                    "description": "ä¸“åˆ©æƒåˆ©è¦æ±‚èŒƒå›´è¾ƒå¹¿",
                    "mitigation": "éœ€è¦è¯¦ç»†çš„æƒåˆ©è¦æ±‚åˆ†æ"
                })
        
        return {
            "high_risk_regions": risk_levels["high"],
            "medium_risk_regions": risk_levels["medium"],
            "low_risk_regions": risk_levels["low"],
            "overall_risk_level": self._calculate_overall_risk(risk_levels),
            "patent_density_map": region_density
        }
    
    def _calculate_overall_risk(self, risk_levels: Dict) -> str:
        """è®¡ç®—æ€»ä½“é£é™©ç­‰çº§"""
        high_count = len(risk_levels["high"])
        medium_count = len(risk_levels["medium"])
        
        if high_count > 2:
            return "é«˜é£é™©"
        elif high_count > 0 or medium_count > 3:
            return "ä¸­ç­‰é£é™©"
        else:
            return "ä½é£é™©"
    
    def _identify_opportunity_regions(self, patents: List, target: str) -> Dict[str, Any]:
        """è¯†åˆ«æœºä¼šåŒºåŸŸ"""
        
        # å·²ä¿æŠ¤åŒºåŸŸ
        protected_areas = set()
        for patent in patents:
            text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
            if "promoter" in text:
                protected_areas.add("promoter")
            if "cpg" in text:
                protected_areas.add("cpg_island")
            if "enhancer" in text:
                protected_areas.add("enhancer")
            if "exon" in text:
                protected_areas.add("exon")
        
        # æ½œåœ¨æœºä¼šåŒºåŸŸ
        all_regions = {
            "promoter": f"{target}å¯åŠ¨å­åŒºåŸŸ",
            "cpg_island": f"{target} CpGå²›",
            "enhancer": f"{target}å¢å¼ºå­",
            "intron_enhancer": f"{target}å†…å«å­å¢å¼ºå­",
            "utr_3": f"{target} 3'UTRè°ƒæ§åŒºåŸŸ",
            "distant_enhancer": f"{target}è¿œç«¯å¢å¼ºå­(+50kb)",
            "silencer": f"{target}æ²‰é»˜å­åŒºåŸŸ",
            "insulator": f"{target}ç»ç¼˜å­åŒºåŸŸ"
        }
        
        opportunity_regions = []
        for region_key, region_desc in all_regions.items():
            if region_key not in protected_areas:
                opportunity_regions.append({
                    "region": region_desc,
                    "opportunity_level": self._assess_opportunity_level(region_key),
                    "rationale": self._generate_opportunity_rationale(region_key, target),
                    "suggested_applications": self._suggest_applications(region_key)
                })
        
        return {
            "unprotected_regions": opportunity_regions,
            "white_space_analysis": self._analyze_white_spaces(protected_areas, target),
            "innovation_opportunities": self._identify_innovation_gaps(patents, target)
        }
    
    def _assess_opportunity_level(self, region_key: str) -> str:
        """è¯„ä¼°æœºä¼šç­‰çº§"""
        high_value_regions = ["intron_enhancer", "utr_3", "distant_enhancer"]
        medium_value_regions = ["silencer", "insulator"]
        
        if region_key in high_value_regions:
            return "é«˜æœºä¼š"
        elif region_key in medium_value_regions:
            return "ä¸­ç­‰æœºä¼š"
        else:
            return "ä¸€èˆ¬æœºä¼š"
    
    def _generate_opportunity_rationale(self, region_key: str, target: str) -> str:
        """ç”Ÿæˆæœºä¼šç†ç”±"""
        rationales = {
            "intron_enhancer": "å†…å«å­å¢å¼ºå­è°ƒæ§æœºåˆ¶ç ”ç©¶è¾ƒå°‘ï¼Œä¸“åˆ©ä¿æŠ¤ç©ºç™½",
            "utr_3": "3'UTRè¡¨è§‚è°ƒæ§æ˜¯æ–°å…´é¢†åŸŸï¼Œä¸“åˆ©å¸ƒå±€æœºä¼šå¤§",
            "distant_enhancer": "è¿œç«¯å¢å¼ºå­è¡¨è§‚ç¼–è¾‘æŠ€æœ¯å°šæœªæˆç†Ÿ",
            "silencer": "æ²‰é»˜å­è¡¨è§‚ç¼–è¾‘å…·æœ‰ç‹¬ç‰¹çš„æ²»ç–—ä»·å€¼",
            "insulator": "ç»ç¼˜å­åŠŸèƒ½è°ƒæ§æ˜¯å‰æ²¿ç ”ç©¶æ–¹å‘"
        }
        return rationales.get(region_key, f"{target}è¯¥åŒºåŸŸä¸“åˆ©ä¿æŠ¤ç›¸å¯¹ç©ºç™½")
    
    def _suggest_applications(self, region_key: str) -> List[str]:
        """å»ºè®®åº”ç”¨æ–¹å‘"""
        applications = {
            "intron_enhancer": ["å¢å¼ºå­æ¿€æ´»", "è¿œç¨‹è°ƒæ§", "ç»„ç»‡ç‰¹å¼‚æ€§è¡¨è¾¾"],
            "utr_3": ["mRNAç¨³å®šæ€§è°ƒæ§", "ç¿»è¯‘åä¿®é¥°", "miRNAé¶ç‚¹ç¼–è¾‘"],
            "distant_enhancer": ["è¿œç¨‹è½¬å½•æ¿€æ´»", "æŸ“è‰²è´¨loopå½¢æˆ", "è¡¨è§‚ä¿®é¥°ä¼ æ’­"],
            "silencer": ["åŸºå› æ²‰é»˜", "å¼‚æŸ“è‰²è´¨å½¢æˆ", "è½¬å½•æŠ‘åˆ¶"],
            "insulator": ["æŸ“è‰²è´¨è¾¹ç•Œ", "è½¬å½•å¹²æ‰°é˜»æ–­", "å¢å¼ºå­ç»ç¼˜"]
        }
        return applications.get(region_key, ["è¡¨è§‚ç¼–è¾‘åº”ç”¨", "è°ƒæ§æœºåˆ¶ç ”ç©¶"])
    
    def _analyze_white_spaces(self, protected_areas: set, target: str) -> Dict[str, Any]:
        """åˆ†æä¸“åˆ©ç©ºç™½"""
        return {
            "protected_count": len(protected_areas),
            "unprotected_count": 8 - len(protected_areas),  # å‡è®¾8ä¸ªä¸»è¦åŒºåŸŸ
            "protection_coverage": f"{len(protected_areas)/8*100:.1f}%",
            "white_space_percentage": f"{(8-len(protected_areas))/8*100:.1f}%"
        }
    
    def _identify_innovation_gaps(self, patents: List, target: str) -> List[str]:
        """è¯†åˆ«åˆ›æ–°ç¼ºå£"""
        gaps = []
        
        # æ£€æŸ¥æŠ€æœ¯ç¼ºå£
        tech_keywords = ["single-cell", "multiplex", "programmable", "reversible", "temporal"]
        found_tech = set()
        
        for patent in patents:
            text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
            for tech in tech_keywords:
                if tech in text:
                    found_tech.add(tech)
        
        missing_tech = set(tech_keywords) - found_tech
        for tech in missing_tech:
            if tech == "single-cell":
                gaps.append("å•ç»†èƒè¡¨è§‚ç¼–è¾‘æŠ€æœ¯ç©ºç™½")
            elif tech == "multiplex":
                gaps.append("å¤šé‡è¡¨è§‚ç¼–è¾‘ç¼ºä¹ä¸“åˆ©ä¿æŠ¤")
            elif tech == "programmable":
                gaps.append("å¯ç¼–ç¨‹è¡¨è§‚å¼€å…³æŠ€æœ¯æœºä¼š")
            elif tech == "reversible":
                gaps.append("å¯é€†è¡¨è§‚ä¿®é¥°æŠ€æœ¯ç©ºç™½")
            elif tech == "temporal":
                gaps.append("æ—¶é—´æ§åˆ¶è¡¨è§‚ç¼–è¾‘æŠ€æœ¯æœºä¼š")
        
        return gaps
    
    def _generate_grna_design_recommendations(self, protected_regions: Dict, risk_assessment: Dict, 
                                            opportunity_regions: Dict, target: str) -> List[str]:
        """ç”ŸæˆgRNAè®¾è®¡å»ºè®®"""
        recommendations = []
        
        # åŸºäºé£é™©è¯„ä¼°çš„å»ºè®®
        if risk_assessment.get("high_risk_regions"):
            recommendations.append(f"é¿å¼€{target}å¯åŠ¨å­æ ¸å¿ƒåŒºåŸŸ(-200bpåˆ°+100bp)çš„gRNAè®¾è®¡")
            recommendations.append("é«˜é£é™©åŒºåŸŸéœ€è¦è¯¦ç»†çš„ä¸“åˆ©æƒåˆ©è¦æ±‚åˆ†æ")
        
        # åŸºäºæœºä¼šåŒºåŸŸçš„å»ºè®®
        opportunities = opportunity_regions.get("unprotected_regions", [])
        if opportunities:
            for opp in opportunities[:3]:
                if "å†…å«å­å¢å¼ºå­" in opp["region"]:
                    recommendations.append("å¯é‡ç‚¹è€ƒè™‘å†…å«å­å¢å¼ºå­çš„è¡¨è§‚ç¼–è¾‘ç­–ç•¥")
                elif "3'UTR" in opp["region"]:
                    recommendations.append("3'UTRåŒºåŸŸå¯ä½œä¸ºå®‰å…¨çš„ç¼–è¾‘é¶ç‚¹")
                elif "è¿œç«¯å¢å¼ºå­" in opp["region"]:
                    recommendations.append("è€ƒè™‘ç”³è¯·è¿œç«¯å¢å¼ºå­è¡¨è§‚ç¼–è¾‘çš„æ–¹æ³•ä¸“åˆ©")
        
        # æŠ€æœ¯ç­–ç•¥å»ºè®®
        recommendations.extend([
            "è®¾è®¡æ—¶ä¼˜å…ˆé€‰æ‹©ä¸“åˆ©ä¿æŠ¤ç©ºç™½åŒºåŸŸ",
            "è€ƒè™‘å¼€å‘åŒºåŸŸç‰¹å¼‚æ€§è¡¨è§‚ç¼–è¾‘å·¥å…·",
            "å»ºè®®è¿›è¡ŒFTO(æ“ä½œè‡ªç”±åº¦)è¯¦ç»†åˆ†æ",
            "å¯æ¢ç´¢æ–°å‹è¡¨è§‚ç¼–è¾‘æœºåˆ¶çš„ä¸“åˆ©å¸ƒå±€"
        ])
        
        return recommendations
    
    def _assess_freedom_to_operate(self, protected_regions: Dict, target: str) -> Dict[str, Any]:
        """è¯„ä¼°æ“ä½œè‡ªç”±åº¦"""
        total_regions = sum(len(regions) for regions in protected_regions.values())
        
        if total_regions > 10:
            fto_level = "å—é™"
            fto_score = 3
        elif total_regions > 5:
            fto_level = "ä¸­ç­‰"
            fto_score = 6
        else:
            fto_level = "è‰¯å¥½"
            fto_score = 9
        
        return {
            "fto_level": fto_level,
            "fto_score": fto_score,
            "total_protected_regions": total_regions,
            "key_restrictions": self._identify_key_restrictions(protected_regions),
            "recommended_actions": self._generate_fto_recommendations(fto_level, total_regions)
        }
    
    def _identify_key_restrictions(self, protected_regions: Dict) -> List[str]:
        """è¯†åˆ«å…³é”®é™åˆ¶"""
        restrictions = []
        
        if protected_regions.get("promoter_regions"):
            restrictions.append("å¯åŠ¨å­åŒºåŸŸå—å¤šé¡¹ä¸“åˆ©ä¿æŠ¤")
        if protected_regions.get("cpg_islands"):
            restrictions.append("CpGå²›ç”²åŸºåŒ–é¶ç‚¹å—é™")
        if len(protected_regions.get("enhancer_regions", [])) > 2:
            restrictions.append("å¢å¼ºå­ç¼–è¾‘é€‰æ‹©å—é™")
        
        return restrictions
    
    def _generate_fto_recommendations(self, fto_level: str, total_regions: int) -> List[str]:
        """ç”ŸæˆFTOå»ºè®®"""
        if fto_level == "å—é™":
            return [
                "å»ºè®®è¿›è¡Œè¯¦ç»†çš„ä¸“åˆ©ä¾µæƒåˆ†æ",
                "è€ƒè™‘ä¸ä¸“åˆ©æƒäººè°ˆåˆ¤è®¸å¯åè®®",
                "æ¢ç´¢è®¾è®¡ç»•è¿‡ç­–ç•¥",
                "é‡ç‚¹å…³æ³¨ä¸“åˆ©ç©ºç™½åŒºåŸŸ"
            ]
        elif fto_level == "ä¸­ç­‰":
            return [
                "å»ºè®®è¿›è¡Œé‡ç‚¹ä¸“åˆ©æƒåˆ©è¦æ±‚åˆ†æ",
                "åˆ¶å®šé£é™©ç¼“è§£ç­–ç•¥",
                "è€ƒè™‘éƒ¨åˆ†åŒºåŸŸçš„è®¸å¯éœ€æ±‚"
            ]
        else:
            return [
                "å½“å‰æ“ä½œè‡ªç”±åº¦è¾ƒå¥½",
                "å»ºè®®ä¸»åŠ¨å¸ƒå±€ç›¸å…³ä¸“åˆ©",
                "å¯å¤§èƒ†è¿›è¡ŒæŠ€æœ¯å¼€å‘"
            ]
    
    def _assess_licensing_needs(self, patents: List, target: str) -> Dict[str, Any]:
        """è¯„ä¼°è®¸å¯éœ€æ±‚"""
        critical_patents = []
        
        for patent in patents[:5]:
            text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
            
            # è¯†åˆ«å…³é”®åŸºç¡€ä¸“åˆ©
            if ("broad" in text or "fundamental" in text) and target.lower() in text:
                critical_patents.append({
                    "patent_id": patent.patent_id,
                    "licensing_priority": "é«˜ä¼˜å…ˆçº§",
                    "rationale": "åŸºç¡€æ€§ä¸“åˆ©ï¼Œéš¾ä»¥è®¾è®¡ç»•è¿‡",
                    "patent_holder": patent.assignee,
                    "estimated_royalty": "3-8%"
                })
        
        return {
            "critical_patents": critical_patents,
            "licensing_priority": "é«˜ä¼˜å…ˆçº§" if critical_patents else "ä½ä¼˜å…ˆçº§",
            "estimated_total_royalty": f"{len(critical_patents)*3}-{len(critical_patents)*8}%",
            "negotiation_strategy": self._suggest_licensing_strategy(critical_patents)
        }
    
    def _suggest_licensing_strategy(self, critical_patents: List) -> List[str]:
        """å»ºè®®è®¸å¯ç­–ç•¥"""
        if not critical_patents:
            return ["å½“å‰æ— æ˜æ˜¾è®¸å¯éœ€æ±‚"]
        
        if len(critical_patents) > 3:
            return [
                "å»ºè®®æ‰“åŒ…è®¸å¯è°ˆåˆ¤",
                "è€ƒè™‘äº¤å‰è®¸å¯åè®®",
                "è¯„ä¼°ä¸“åˆ©æ± åŠ å…¥å¯èƒ½æ€§"
            ]
        else:
            return [
                "å¯è¿›è¡Œå•ç‹¬è®¸å¯è°ˆåˆ¤",
                "é‡ç‚¹å…³æ³¨æ ¸å¿ƒä¸“åˆ©è®¸å¯",
                "è€ƒè™‘å¼€å‘å·®å¼‚åŒ–æŠ€æœ¯è·¯å¾„"
            ]
    
    def _extract_research_purpose(self, patent, target: str) -> Dict[str, Any]:
        """ä»ä¸“åˆ©ä¸­æå–ç ”ç©¶ç›®çš„"""
        text = (patent.title + " " + getattr(patent, 'abstract', '')).lower()
        
        # ç ”ç©¶ç›®çš„å…³é”®è¯æ˜ å°„
        purpose_patterns = {
            "æ²»ç–—åº”ç”¨": ["treatment", "therapy", "therapeutic", "cure", "heal"],
            "è¯Šæ–­æ£€æµ‹": ["diagnostic", "detection", "screening", "assay", "biomarker"],
            "é¢„é˜²å¹²é¢„": ["prevention", "prophylaxis", "preventive", "protect"],
            "æœºåˆ¶ç ”ç©¶": ["mechanism", "pathway", "interaction", "regulation", "function"],
            "è¯ç‰©å¼€å‘": ["drug", "pharmaceutical", "compound", "inhibitor", "agonist"],
            "åŸºå› ç¼–è¾‘": ["crispr", "editing", "modification", "knockout", "knockdown"],
            "è¡¨è§‚è°ƒæ§": ["epigenetic", "methylation", "histone", "chromatin", "modification"]
        }
        
        identified_purposes = []
        primary_category = "å…¶ä»–ç ”ç©¶"
        
        for category, keywords in purpose_patterns.items():
            if any(keyword in text for keyword in keywords):
                identified_purposes.append(category)
                if not primary_category or primary_category == "å…¶ä»–ç ”ç©¶":
                    primary_category = category
        
        # æå–å…·ä½“ç ”ç©¶èƒŒæ™¯
        background_indicators = []
        if target.lower() in text:
            background_indicators.append(f"{target}ç›¸å…³ç ”ç©¶")
        if "cancer" in text or "tumor" in text:
            background_indicators.append("è‚¿ç˜¤ç›¸å…³")
        if "disease" in text:
            background_indicators.append("ç–¾ç—…ç›¸å…³")
        
        return {
            "patent_id": patent.patent_id,
            "title": patent.title,
            "purpose": identified_purposes[0] if identified_purposes else "æœªè¯†åˆ«",
            "category": primary_category,
            "all_purposes": identified_purposes,
            "research_background": background_indicators,
            "innovation_focus": self._identify_innovation_focus(text)
        }
    
    def _identify_innovation_focus(self, text: str) -> str:
        """è¯†åˆ«åˆ›æ–°é‡ç‚¹"""
        if "novel" in text or "new" in text:
            return "æ–°é¢–æ€§åˆ›æ–°"
        elif "improved" in text or "enhanced" in text:
            return "æ”¹è¿›å‹åˆ›æ–°"
        elif "efficient" in text or "effective" in text:
            return "æ•ˆç‡æå‡"
        elif "specific" in text or "selective" in text:
            return "ç‰¹å¼‚æ€§å¢å¼º"
        else:
            return "ç»¼åˆæ€§åˆ›æ–°"
    
    def get_analysis_summary(self, result: PatentAnalysisResult) -> str:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        summary = f"""
{result.target} ä¸“åˆ©åˆ†ææ‘˜è¦ï¼š

ğŸ“Š ä¸“åˆ©æ¦‚å†µï¼š
- æ€»ä¸“åˆ©æ•°ï¼š{result.total_patents}
- åˆ›æ–°å¼ºåº¦ï¼š{result.landscape_analysis.get('innovation_intensity', 'N/A')}
- å¸‚åœºæˆç†Ÿåº¦ï¼š{result.landscape_analysis.get('market_maturity', 'N/A')}

ğŸ¢ ä¸»è¦å‚ä¸è€…ï¼š
"""
        for player in result.landscape_analysis.get('key_players', [])[:3]:
            summary += f"- {player['name']}ï¼š{player['patents']}é¡¹ä¸“åˆ©ï¼ˆ{player['market_share']}%å¸‚åœºä»½é¢ï¼‰\n"
        
        summary += f"""
ğŸ“ˆ æŠ€æœ¯è¶‹åŠ¿ï¼š
- ç”³è¯·è¶‹åŠ¿ï¼š{result.trend_analysis.get('filing_trend', 'N/A')}
- é¢„æµ‹ï¼š{result.trend_analysis.get('forecast', 'N/A')}

ğŸ’¡ å…³é”®æ´å¯Ÿï¼š
"""
        for i, insight in enumerate(result.competitive_insights[:3], 1):
            summary += f"{i}. {insight}\n"
        
        summary += f"""
ğŸ¯ å»ºè®®ï¼š
"""
        for i, rec in enumerate(result.recommendations[:3], 1):
            summary += f"{i}. {rec}\n"
        
        summary += f"""
ğŸ“Š åˆ†æå¯ä¿¡åº¦ï¼š{result.confidence_score:.0%}
âš¡ Tokenä½¿ç”¨ï¼š{result.token_usage}
"""
        
        return summary


# æµ‹è¯•å‡½æ•°
async def test_patent_expert():
    """æµ‹è¯•ä¸“åˆ©ä¸“å®¶åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ä¸“åˆ©ä¸“å®¶æ™ºèƒ½ä½“")
    print("=" * 50)
    
    # æµ‹è¯•ä¸åŒé…ç½®æ¨¡å¼
    configs = {
        "QUICK": ConfigManager.get_quick_config(),
        "STANDARD": ConfigManager.get_standard_config(),
        "DEEP": ConfigManager.get_deep_config()
    }
    
    target = "DNMT1"
    context = {
        "patent_focus_areas": ["therapy", "diagnostic"],
        "additional_terms": ["methylation", "cancer"]
    }
    
    for mode, config in configs.items():
        print(f"\nğŸ“‹ æµ‹è¯• {mode} æ¨¡å¼:")
        
        try:
            expert = PatentExpert(config)
            result = await expert.analyze(target, context)
            
            print(f"âœ… åˆ†ææˆåŠŸ")
            print(f"   - æ€»ä¸“åˆ©æ•°ï¼š{result.total_patents}")
            print(f"   - ç½®ä¿¡åº¦ï¼š{result.confidence_score:.0%}")
            print(f"   - Tokenä½¿ç”¨ï¼š{result.token_usage}")
            print(f"   - å…³é”®ä¸“åˆ©ï¼š{len(result.key_patents)}")
            print(f"   - å»ºè®®æ•°ï¼š{len(result.recommendations)}")
            
            # æ‰“å°æ‘˜è¦
            if mode == "STANDARD":
                print("\nğŸ“„ åˆ†ææ‘˜è¦ï¼š")
                print(expert.get_analysis_summary(result))
                
        except Exception as e:
            print(f"âŒ {mode} æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_patent_expert())